<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="Distributome.css" type="text/css"?>
<distributome version="1.1" 
	xmlns="http://www.distributome.org" 
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
	xsi:schemaLocation="http://www.distributome.org/distributome.xsd">

<distributions>
<distribution id="arcsine">
	<name>arcsine distribution</name>
	<name>Levy arcsine distribution</name>
	<type>continuous</type>
	<model>The arcsine distribution models the proportion of time that Brownian motion is positive.</model>
	<support>\((0, 1)\)</support>
	<pdf>\(f(x) = \frac{1}{\pi \sqrt{x (1 - x)}}, \; x \in (0, 1)\)</pdf>
	<mode>Does not exist</mode>
	<cdf>\(F(x) = \frac{2}{\pi} \arcsin(\sqrt{x}), \; x \in (0, 1)\)</cdf>
	<qf>\(Q(p) = \sin^2(\frac{\pi}{2} p), \; p \in (0, 1)\)</qf>
	<mean>\(\frac{1}{2}\)</mean>
	<variance>\(\frac{1}{8}\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(\frac{33}{4}\)</kurt>
	<median>\(\frac{1}{2}\)</median>
	<q1>\(\frac{2 - \sqrt{2}}{4}\)</q1>
	<q3>\(\frac{2 + \sqrt{2}}{4}\)</q3>
	<history>Derived by Paul Levy in 1939 as the distribution of proportion of time that Brownian motion is  positive.</history>
</distribution>

<distribution id="Bernoulli">
	<name>Bernoulli distribution</name>
	<type>discrete</type>
	<model>The Bernoulli distribution governs an indicator random variable.</model>
	<parameter>\(p \in [0, 1]\), the probability of the event</parameter>
	<support>\(\{0, 1\}\)</support>
	<pdf>\(f(x) = p^x (1 - p)^{1 - x}, \; x \in \{0, 1\}\)</pdf>
	<mode>\(\lfloor 2 p \rfloor\)</mode>
	<cdf>\(F(x) = (1 - p)^{1 - x}, \; x \in \{0, 1\}\)</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<pgf>\(G(t) = 1 - p + p t, \; t \in (-\infty, \infty)\)</pgf>
	<mgf>\(M(t) = 1 - p + p e^t, \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = 1 - p + p e^{i t}, \; t \in (-\infty, \infty)\)</cf>
	<moments type="raw">\(\mu(n) = p, \; n \in \{0, 1, \ldots\}\)</moments>
	<mean>\(p\)</mean>
	<variance>\(p (1-p)\)</variance>
	<skew>\(\frac{1 - 2 p}{\sqrt{p (1 - p)}}\)</skew>
	<kurt>\(\frac{1- 6 p + 6 p^2}{p (1 - p)}\)</kurt>
	<entropy>\(-(1 - p) \ln(1 - p) - p \ln(p)\)</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>power series </family>
	<family>exponential</family>
	<history>Named for Jacob Bernoulli</history>
</distribution>

<distribution id="beta">
	<name>beta distribution</name>
	<type>continuous</type>
	<model>The beta distribution is used to model random proportions and probabilities. </model>
	<parameter>\(\alpha \in (0, \infty)\), the left shape parameter</parameter>
	<parameter>\(\beta \in (0, \infty)\), the right shape parameter</parameter>
	<support>\((0, 1)\)</support>
	<pdf>\(f(x) = \frac{1}{B(\alpha, \beta)} x^{\alpha - 1} (1 - x)^{\beta - 1}, \; x \in (0, 1)\)</pdf>
	<mode>\(\frac{\alpha - 1}{\alpha + \beta - 2}; \; \alpha \in (1, \infty), \beta \in (1, \infty)\)</mode>
	<cdf>\(F(x) = \int_0^x f(t) dt\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\), where \(F\) is the distribution function.</qf>
	<mgf>\(M(t) = 1 + \sum_{k=1}^\infty \left(\prod_{j=0}^{k-1} \frac{\alpha + j}{\alpha + \beta + j}\right) \frac{t^k}{k!}, \; t \in (-\infty, \infty)\)</mgf>
	<mean>\(\frac{\alpha}{\alpha + \beta}\)</mean>
	<variance>\(\frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}\)</variance>
	<skew>\(\frac{2 (\beta - \alpha) \sqrt{\alpha + \beta + 1}}{(\alpha + \beta + 2) \sqrt{\alpha \beta}}\)</skew>
	<kurt>\(\frac{\alpha^3 - \alpha^2 (2 \beta - 1) + \beta^2 (\beta + 1) - 2 \alpha \beta (\beta + 2)}{\alpha \beta (\alpha + \beta + 2)(\alpha + \beta + 3)}\)</kurt>
	<entropy>\(\ln(B(\alpha, \beta)) - (\alpha - 1) \psi(\alpha) - (\beta - 1) \psi(\beta) + (\alpha + \beta - 2) \psi(\alpha + \beta)\) where \(\psi\) is the digamma function</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>exponential</family>
</distribution>

<distribution id="inverse beta">
	<name>inverse beta distribution</name>
	<type>continuous</type>
	<model>The inverse beta distribution, as the name suggests, is the inverse probability dsitribution of a Beta-distributed variable. </model>
	<parameter>\(\alpha \in (0, \infty)\), the left shape parameter</parameter>
	<parameter>\(\beta \in (0, \infty)\), the right shape parameter</parameter>
	<support>\((0, 1)\)</support>
	<family>exponential</family>
</distribution>

<distribution id="binomial">
	<name>binomial distribution</name>
	<type>discrete</type>
	<model>The binomial distribution models the number of successes in a fixed number of independent trials each with the same probability of success.</model>
	<parameter>\(n \in \{1, 2, \ldots\}\), the number of trials</parameter>
	<parameter>\(p \in [0, 1]\), the probability of success</parameter>
	<support>\(\{0, 1, \ldots, n\}\)</support>
	<pdf>\(f(x) = {n \choose x} p^x (1 - p)^{n - x}, \; x \in \{0, 1, \ldots, n\}\)</pdf>
	<mode>\(\lfloor (n + 1) p \rfloor\)</mode>
	<cdf>\(F(x) = B(1 - p; n - x, x + 1), \; x \in \{0, 1, \ldots, n\}\) where \(B\) is the incomplete beta function</cdf>
	<qf>\(Q(r) = F^{-1}(r), \; r \in [0, 1]\) where \(F\) is the distribution function</qf>
	<pgf>\(G(t) = (1 - p + p t)^n, \; t \in (-\infty, \infty)\)</pgf>
	<mgf>\(M(t) = (1 - p + p e^t)^n, \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = (1 - p + p e^{i t})^n, \; t \in (-\infty, \infty)\)</cf>
	<mean>\(n p\)</mean>
	<variance>\(n p (1 - p)\)</variance>
	<skew>\(\frac{1 - 2 p}{\sqrt{n p (1 - p)}}\)</skew>
	<kurt>\(\frac{1 - 6 p (1 - p)}{n p (1 - p)}\)</kurt>
	<entropy>\(\frac{1}{2} \log_2[2 \pi e n p (1 - p)] + O\left(\frac{1}{n}\right)\)</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{1}{3})\) where \(Q\) is the quantile function</q3>
	<family>power series </family>
	<family>exponential</family>
	<history>The binomial distribution is attributed to Jacob Bernoulli</history>
</distribution>

<distribution id="beta-binomial">
	<name>beta-binomial distribution</name>
	<type>discrete</type>
	<model>The beta-binomial distribution arises when the success parameter in the binomial distribution is randomized and given a beta distribution.</model>
	<parameter>\(n \in \{1, 2, \ldots\}\), the number of trials</parameter>
	<parameter>\(a \in (0, \infty)\), the left beta parameter</parameter>
	<parameter>\(b \in (0, \infty)\), the right beta parameter</parameter>
	<support>\(\{0, 1, \ldots, n\}\)</support>
	<pdf>\(f(x) = {n \choose x} \frac{B(a + x) B(b + n - x)}{B(a, b)}, \; x \in \{0, 1, \ldots, n\}\), where \(B\) is the beta function</pdf>
	<cdf>\(F(x) = \sum_0^x f(t), \quad x \in \{0, 1, \ldots, n\}\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(n \frac{a}{a + b}\)</mean>
	<variance>\(n \frac{a b}{(a + b)^2} \frac{a + b + n}{a + b + 1}\)</variance>
	<skew>\(\frac{(a + b + 2n)(b - a)}{(a + b + 2)} \sqrt{\frac{1 + a + b}{b a b (n + a + b)}}\)</skew>
	<kurt>\(\frac{(a + b)^2 ( + 1 + b)}{n a b (a + b + 2)(a + b + 3)(a + b + n)} \left[(a + b)(a + b - 1 + 6 n) + 3 a b (n - 2) + 6 n^2 - \frac{3 a b n (6-n)}{a + b} - \frac{18 a b n^2}{(a + b)^2}\right]\)</kurt>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
</distribution>

<distribution id="Cauchy">
	<name>Cauchy distribution </name>
	<name>Cauchy-Lorentz distribution </name>
	<name>Lorentz distribution </name>
	<name>Breit-Wigner distribution</name>
	<type>continuous</type>
	<model>The general Cauchy distribution is the location-scale family associated with the standard Cauchy distribution </model>
	<parameter>\(\alpha \in (-\infty, \infty)\). the location parameter</parameter>
	<parameter>\(\beta \in (0, \infty)\), the scale parameter</parameter>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{\pi} \frac{\beta}{(x - \alpha)^2 + \beta^2}, \; x \in (-\infty, i\infty)\)</pdf>
	<mode>\(\alpha\)</mode>
	<cdf>\(F(x) = \frac{1}{2} + \frac{1}{\pi} \arctan \left(\frac{x - \alpha}{\beta} \right),  \; x \in (-\infty, \infty)\)</cdf>
	<qf>\(Q(p) = F^{-1}(p) = \alpha + \beta \tan \left(\pi (p - \frac{1}{2} \right), \; p \in (0, 1)\)</qf>
	<mgf>Does not exist</mgf>
	<cf>\(\varphi(t) = \exp(\alpha i t - \beta |t|), \; t \in (-\infty, \infty)\)</cf>
	<mean>Does not exist</mean>
	<variance>Does not exist</variance>
	<skew>Does not exist</skew>
	<kurt>Does not exist</kurt>
	<entropy>\(\ln (4 \pi \beta\)</entropy>
	<median>\(\alpha\)</median>
	<q1>\(\alpha - \beta\)</q1>
	<q3>\(\alpha + \beta\)</q3>
	<family>location </family>
	<family>scale </family>
	<family>stable</family>
	<history>The distribution was first used by Simeon Poisson in 1824 and was re-introduced by Augustin Cauchy in 1853. It is also named for Hendrick Lorentz.</history>
</distribution>

<distribution id="chi-square">
	<name>chi-square distribution </name>
	<name>chi-squared distribution</name>
	<type>continuous</type>
	<model>The chi-square distribution governs the sum of squares of independent standard normal variable.</model>
	<parameter>\(n \in (0, \infty)\), degrees of freedom</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{2^{n/2} \Gamma(n/2)} x^{n/2-1} e^{-x/2}, \; x \in (0, \infty)\)</pdf>
	<mode>\(n-2, \; n \in [2, \infty)\)</mode>
	<cdf>\(F(x) = \frac{1}{\Gamma(n/2)} \gamma(x/2; n/2)\) where \(\gamma\) is the lower incomplete gamma function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in [0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>\(M(t) = \frac{1}{(1 - 2 t)^{n/2}}, \; t \in (-\infty, \frac{1}{2})\)</mgf>
	<cf>\(\frac{1}{(1 - 2 i t^{n/2}}) \; t \in (-\infty, \infty)\)</cf>
	<mean>\(n\)</mean>
	<variance>\(2 n\)</variance>
	<skew>\(\sqrt{8/n}\)</skew>
	<kurt>\(12/n\)</kurt>
	<entropy>\(n/2 + \ln(2 \Gamma(n/2)) + (1 - k/2) \psi(n/2)\) where \(\psi\) is the digamma function</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>exponential</family>
	<history>The chi-square distribution was first used by Karl Pearson in 1900.</history>
</distribution>

<distribution id="chi">
	<name>chi distribution</name>
	<type>continuous</type>
	<model>The chi distribution governs the square root of a variable with the chi-square distribtion.</model>
	<parameter>\(n \in \{1, 2, \ldots\}\), the degrees of freedom</parameter>
	<support>\([0, \infty)\)</support>
	<pdf>\(f(x) = \frac{2^{1-n/2}}{\Gamma(n/2)} x^{n-1} e^{-x^2/2}, \; x \in [0, \infty)\) where \(\Gamma\) is the gamma function</pdf>
	<mode>\(\sqrt{n - 1}\)</mode>
	<cdf>\(F(x) = \int_0^x f(t) dt, \; x \in \) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<moments type="raw">\(\mu(k) = \frac{2^{k/2} \Gamma[(n+k)/2)]}{\Gamma(n/2)}, \; n \in \{1, 2, \ldots\}\) where \(\Gamma\) is the gamma function</moments>
	<mean>\(\sqrt{2} \frac{\Gamma[(n+1)/2]}{\Gamma(n/2)}\) where \(\Gamma\) is the gamma function</mean>
	<variance>\(n - \mu^2\) where \(\mu\) is the mean.</variance>
	<skew>\(\frac{\mu}{\sigma^3} (1 - 2 \sigma^2)\) where \(\mu\) is the mean and \(\sigma\) the standard deviation</skew>
	<kurt>\(\frac{2}{\sigma^2} (1 - \mu \sigma \gamma_1 - \sigma^2)\) where \(\mu\) is the mean, \(\sigma\) the standard deviation, and \(\gamma_1\) the skewness</kurt>
	<entropy>\(\ln[\Gamma(n/2)] + \frac{1}{2} [n - \ln(2) - (n-1) \psi_0(n/2)]\) where \(\psi_0\) is the polygamma function</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
</distribution>

<distribution id="continuous-uniform">
	<name>continuous uniform distribution </name>
	<name>rectangular distribution</name>
	<type>continuous</type>
	<model>The continuous uniform distribution governs a point chosen at random from an interval.</model>
	<parameter>\(a \in (-\infty, \infty)\), the left endpoint</parameter>
	<parameter>\(b \in (a, \infty)\), the right endpoint</parameter>
	<support>\([a, b]\)</support>
	<pdf>\(f(x) = \frac{1}{b - a}, \; x \in [a, b]\)</pdf>
	<mode> all \(x \in [a, b]\)</mode>
	<cdf>\(F(x) = \frac{x - a}{b - a}, \; x \in [a, b]\)</cdf>
	<qf>\(Q(p) = a + p (b - a). \; p \in [0, 1]\)</qf>
	<mgf>\(M(t) = \frac{e^{t b} - e^{t a}}{t (b - a)}, \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = \frac{e^{i t b} - e^{i t a}}{i t (b - a)}, \; t \in (-\infty, \infty)\)</cf>
	<moments type="raw">\(\mu(t) = \frac{b^{t+1} - a^{t+1}}{(t + 1)(b - a)}, \; t \in (0, \infty)\)</moments>
	<mean>\(\frac{1}{2}(a + b)\)</mean>
	<variance>\(\frac{1}{12} (b - a)^2\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(-\frac{6}{5}\)</kurt>
	<entropy>\(\ln(b - a)\)</entropy>
	<median>\(\frac{1}{2}(a + b)\)</median>
	<q1>\(\frac{3}{4} a + \frac{1}{4}b\)</q1>
	<q3>\(\frac{1}{4} a + \frac{3}{4} b\)</q3>
	<family>location </family>
	<family>scale</family>
</distribution>

<distribution id="discrete-uniform">
	<name>discrete uniform distribution</name>
	<type>discrete</type>
	<model>The discrete uniform distribution governs a point chosen at random from an integer interval.</model>
	<parameter>\(a \in \{\ldots -2, -1, 0, 1, 2, \ldots\}\), the left endpoint</parameter>
	<parameter>\(b \in \{a, a+1, \ldots\}\), the right endpoint</parameter>
	<support>\(\{a, a+1, \ldots, b\}\)</support>
	<pdf>\(f(x) = \frac{1}{b - a + 1}, \; x \in \{a, a+1, \ldots, b\}\)</pdf>
	<mode>all \(x \in \{a, a+1, \ldots, b\}\)</mode>
	<cdf>\(F(x) = \frac{x - a + 1}{b - a + 1}, \; x \in \{a, a+1, \ldots, b\}\)</cdf>
	<qf>\(Q(p) = \lceil a + p (b - a) \rceil, \; p \in [0, 1]\)</qf>
	<mgf>\(M(t) = \frac{e^{a t} - e^{(b+1) t}}{(b + a + 1)(1 - e^t)}, \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = \frac{e^{i a t} - e^{i (b+1) t}}{(b + a + 1)(1 - e^{i t})}, \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\frac{1}{2}(a + b)\)</mean>
	<variance>\(\frac{1}{12}[(b - a + 1)^2 - 1]\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(-\frac{6}{5} \frac{(b - a + 1)^2 + 1}{(b - a + 1)^2 - 1}\)</kurt>
	<entropy>\(\ln(a + b - 1)\)</entropy>
	<median>\(\lceil \frac{1}{2}(a + b) \rceil\)</median>
	<q1>\(\lceil \frac{3}{4} a + \frac{1}{4} b \rceil\)</q1>
	<q3>\(\lceil \frac{1}{4} a + \frac{3}{4} b \rceil\)</q3>
</distribution>

<distribution id="exponential">
	<name>exponential distribution</name>
	<name>negative exponential distribution</name>
	<type>continuous</type>
	<model>The exponential distribution models the time between random points in the Poisson model.</model>
	<parameter>\(r \in (0, \infty)\), rate</parameter>
	<support>\([0, \infty)\)</support>
	<pdf>\(f(x) = r e^{-r x}, \; x \in [0, \infty)\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = 1 - e^{-r x}, \; x \in [0, \infty)\)</cdf>
	<qf>\(Q(p) = \frac{- \ln(1 - p)}{r}, \; p \in [0, 1)\)</qf>
	<mgf>\(\frac{r}{r - t}, \; t \in (-\infty, t)\)</mgf>
	<cf>\(\frac{r}{r - i t}, \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\frac{1}{r}\)</mean>
	<variance>\(\frac{1}{r^2}\)</variance>
	<skew>\(2\)</skew>
	<kurt>\(6\)</kurt>
	<entropy>\(1 - \ln(r)\)</entropy>
	<median>\(\frac{\ln(2)}{r}\)</median>
	<q1>\(\frac{\ln(4) - \ln(3)}{r}\)</q1>
	<q3>\(\frac{\ln(3)}{r}\)</q3>
	<family>exponential </family>
	<family>scale</family>
	<history>The exponential distribution was named by Karl Pearson in 1895.</history>
</distribution>

<distribution id="exponential-logarithmic">
	<name>exponential-logarithmic distribution</name>
	<type>continuous</type>
	<model>The exponential-logarithmic distribution models failure times of devices with decreasing failure rate.</model>
	<parameter>\(p \in (0, 1)\), the shape parameter</parameter>
	<parameter>\(b \in (0, \infty)\), the scale parameter</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = -\frac{1}{p} \frac{b (1 - p) e^{-b x}}{1 - (1 - p) e^{-b x}}, \; x \in [0, \infty)\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = 1 - \frac{\ln(1 - (1 - p) e^{-b x})}{\ln(p)}, \; x \in [0, \infty)\)</cdf>
	<qf>\(Q(r) = \frac{1}{b} \ln\left(\frac{1 - p}{1 - p^{1 - r}}\right), \; r \in (0, 1)\)</qf>
	<moments type="raw">\(\mu(n) = -n! \frac{L_{n+1}(1 - p)}{b^n \ln(p)}, \; n \in \{0, 1, \ldots\}\) where \(L_{n+1}\) is the polylog function of order \(n + 1\)</moments>
	<mean>\(-\frac{L_2(1 - p)}{b \ln(p)}\) where \(L_2\) is the polylog function of order \(2\).</mean>
	<variance>\(-\frac{2 L_3(1 - p)}{b^2 ln(p)} - \frac{L_2^2(1 - p)}{b^2 \ln^2(p)}\) where \(L_n\) is the polylog function of order \(n\)</variance>
	<median>\(\frac{1}{b} \ln(1 +\sqrt{p})\)</median>
	<q1>\(\frac{1}{b} \ln\left(\frac{1 - p}{1 - p^{3/4}}\right)\)</q1>
	<q3>\(\frac{1}{b} \ln\left(\frac{1 - p}{1 - p^{3/4}}\right)\)</q3>
	<family>scale</family>
</distribution>

<distribution id="exponential-power">
	<name>exponential power distribution </name>
	<name>generalized error distribution</name>
	<type>continuous</type>
	<model>The exponential power distribution is a family of symmetric, unimodal distributions that generalizes the normal and Laplace families.</model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(\alpha \in (0, \infty)\), the scale parameter</parameter>
	<parameter>\(\beta \in (0, \infty)\), the shape parameter</parameter>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{\beta}{2 \alpha \Gamma(1/\beta)} \exp\left[-\left(\frac{|x - \mu|}{\alpha}\right)^\beta\right], \; x \in (-\infty, \infty)\) where \(\Gamma\) is the gamma function</pdf>
	<mode>\(\mu\)</mode>
	<cdf>\(F(x) = \frac{1}{2} + \frac{\sgn(x - \mu)}{2 \Gamma (1 / \beta)} \gamma\left[\frac{1}{\beta}, \left(\frac{|x - \mu|}{\alpha}\right)^\beta\right], \; x \in (-\infty, \infty)\), where \(\Gamma\) is the gamma function and \(\gamma\) is the lower incomplete gamma function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(\mu\)</mean>
	<variance>\(\frac{\alpha^2 \Gamma(3/\beta)}{\Gamma(1/\beta)}\) where \(\Gamma\) is the gamma function</variance>
	<skew>\(0\)</skew>
	<kurt>\(\frac{\Gamma(5/\beta) \Gamma(1/\beta)}{\Gamma^2(3/\beta)} - 3\) where \(\Gamma\) is the gamma function</kurt>
	<entropy>\(\frac{1}{\beta} - \log\left[\frac{\beta}{2 \alpha \Gamma(1/\beta)}\right]\) where \(\Gamma\) is the gamma function</entropy>
	<median>\(\mu\)</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>location </family>
	<family>scale</family>
</distribution>

<distribution id="F">
	<name>F-distribution </name>
	<name>Snedecor's F-distribution </name>
	<name>Fisher-Snedecor distribution</name>
	<type>continuous</type>
	<model>The F-distribution governs the ratio of independent, scaled chi-square variables.</model>
	<parameter>\(m \in (0, \infty)\), numerator degrees of freedom</parameter>
	<parameter>\(n \in (0, \infty)\), denominator degrees of freedom</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{x B(m/2, n/2)} \sqrt{\frac{(m x)^m n^n}{(m x + n)^{m+n}}}, \; x \in (0, \infty)\) where \(B\) is the beta function</pdf>
	<mode>\(\frac{m - 2}{m} \frac{n}{n+2}, \; m \in (2, \infty)\)</mode>
	<cdf>\(F(x) = \frac{B(m x/(m x + n); m/2, n/2)}{B(m/2, n/2)}\) where \(B\) is the beta function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>Does not exist</mgf>
	<mean>\(\frac{n}{n - 2}, \; n \in (2, \infty)\)</mean>
	<variance>\(\frac{2 n^2 (m + n - 2)}{m (n - 2)^2 (n - 4)}, \; n \in (4, \infty)\)</variance>
	<skew>\(\frac{(2 m + n - 2) \sqrt{8 (n - 4)}}{(n - 6) \sqrt{m (m + n - 2)}}, \; n \in (6, \infty)\)</skew>
	<kurt>\(\frac{20 n - 8 n^2 + n^3 + 44 m -32 m n + 5 m n^2 - 22 m^2 - 5 m^2 n - 16}{m (n - 6)(n - 8)(m + n - 2)/12}, \; n \in (8, \infty)\)</kurt>
	<median> \(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The \(F\)-distribution was first derived by George Snedecor in 1934.  The letter <em>F</em> was chosen as a tribute to Ronald Fisher.</history>
</distribution>

<distribution id="gamma">
	<name>gamma distribution</name>
	<type>continuous</type>
	<model>The gamma distribution governs the arrival times in the Poisson model.</model>
	<parameter>\(k \in (0, \infty)\), the shape parameter</parameter>
	<parameter>\(\theta \in (0, \infty)\), the scale parameter</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{\Gamma(k) \theta^k} x^{k-1} \exp(-\frac{x}{\theta}), \; x \in (0, \infty)\) where \(\Gamma\) is the gamma function</pdf>
	<mode>\((k - 1) \theta, \; k \in [1, \infty)\)</mode>
	<cdf>\(F(x) = \frac{1}{\Gamma(k)} \gamma(k, \frac{x}{\theta}), \; x \in (0, \infty)\) where \(\Gamma\) is the gamma function and \(\gamma\) the lower incomplete gamma function</cdf>
	<qf>\(Q(p) = F^{-1}(p)\) where \(F\) is the distribution function</qf>
	<mgf>\(M(t) = \frac{1}{(1 - \theta t)^k}, \; t \in (-\infty, 1 / \theta)\)</mgf>
	<cf>\(\varphi(t) = \frac{1}{(1 - i \theta t)^k}, \; t \in (-\infty, \infty)\)</cf>
	<mean>\(k \theta\)</mean>
	<variance>\(k \theta^2\)</variance>
	<skew>\(\frac{2}{\sqrt{k}}\)</skew>
	<kurt>\(k + \ln(\theta) + \ln(\Gamma(k)) + (1 - k) \psi(k)\) where \(\psi\) is the digamma function</kurt>
	<entropy>\(\ln (4 \pi \beta)\)</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1> \(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>scale </family>
	<family>exponential</family>
</distribution>

<distribution id="geometric">
	<name>geometric distribution</name>
	<type>discrete</type>
	<model>The geometric distribution models the trial number of the first success in a sequence of Bernoulli trials.</model>
	<parameter>\(p \in (0, 1]\), the success parameter</parameter>
	<support>\(\{1, 2, \ldots\}\)</support>
	<pdf>\(f(x) = p (1 - p)^{x - 1}, \; x \in \{1, 2, \ldots\}\)</pdf>
	<mode>\(1\)</mode>
	<cdf>\(F(x) = 1 - (1 - p)^x, \; x \in \{1, 2, \ldots\}\)</cdf>
	<qf>\(Q(r) = \lceil \frac{\ln(1 - r)}{\ln(1 - p)} \rceil, \; r \in [0, 1)\)</qf>
	<pgf>\(G(t) = \frac{p t}{1 - (1 - p) t}, \; t \in \left(-\frac{1}{1 - p}, \frac{1}{1 - p}\right)\)</pgf>
	<mgf>\(M(t) = \frac{p e^t}{1 - (1 - p) e^t}, \; t \in (-\infty, -\ln(1 - p))\)</mgf>
	<cf>\(\varphi(t) = \frac{p e^{i t}}{1 - (1 - p) e^{i t}}, \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\frac{1}{p}\)</mean>
	<variance>\(\frac{1 - p}{p^2}\)</variance>
	<skew>\(\frac{2 - p}{\sqrt{1 - p}}\)</skew>
	<kurt>\(6 + \frac{p^2}{1 - p}\)</kurt>
	<entropy>\(-\frac{1}{p}((1 - p) \log_2(1 - p) + p \log_2(p))\)</entropy>
	<median>\(\lceil \frac{-\ln(2)}{\ln(1 - p)} \rceil\)</median>
	<q1>\(\lceil \frac{\ln(3) - \ln(4)}{\ln(1 - p)} \rceil\)</q1>
	<q3>\(\lceil \frac{-\ln(4)}{\ln(1 - p)} \rceil\)</q3>
	<family>power series </family>
	<family>exponential</family>
	<history>The geometric distribution was used very early in the history of probability, but the name has been attributed to William Feller in 1950.</history>
</distribution>

<distribution id="Gumbel">
	<name>Gumbel distribution</name>
	<type>continuous</type>
	<model>The Gumbel distribution models the limit of of the maximum of independent, identically distributed variables.</model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(\sigma \in (0, \infty)\), the scale parameter</parameter>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{\sigma} \exp\left(-\frac{x - \mu}{\sigma}\right) \exp\left(-\exp\left(\frac{x - \mu}{\sigma}\right)\right), \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(\mu\)</mode>
	<cdf>\(F(x) = \exp\left(-\exp\left(\frac{x - \mu}{\sigma}\right)\right), \; x \in (-\infty, \infty)\)</cdf>
	<qf>\(Q(p) = \mu - \sigma \ln(-\ln(p)), \; p \in (0, 1)\)</qf>
	<mgf>\(M(t) = e^{\mu t} \Gamma(1 - \sigma t), \; t \in (-\infty, \frac{1}{\sigma})\)</mgf>
	<mean>\(\mu + \sigma \gamma\) where \(\gamma\) is Euler's constant</mean>
	<variance>\(\frac{\pi^2}{6} \sigma^2\)</variance>
	<skew>\(\frac{12 \sqrt{6}}{\pi^2} \zeta(3)\) where \(\zeta\) is the zeta function</skew>
	<kurt>\(\frac{12}{5}\)</kurt>
	<entropy>\(\ln(\sigma) + \gamma + 1\) where \(\gamma\) is Euler's constant</entropy>
	<median>\(\mu - \sigma \ln(\ln(2))\)</median>
	<q1>\(\mu - \sigma \ln(\ln(4) - \ln(3))\)</q1>
	<q3>\(\mu - \sigma \ln(\ln(4))\)</q3>
	<family>location </family>
	<family>scale</family>
	<history>The Gumbel distribution is named for Emil Gumbel, who derived it in his study of extreme values in 1954.</history>
</distribution>

<distribution id="hypergeometric">
	<name>hypergeometric distribution</name>
	<type>discrete</type>
	<model>The hypergeometric distribution governs the number of objects of a given type when sampling without replacement from a multi-type population.</model>
	<parameter>\(N\), the population size</parameter>
	<parameter>\(m\), the number of type 1 objects in the population</parameter>
	<parameter>\(n\), the sample size</parameter>
	<support>\(\{\max(0, n + m - N), \ldots, \min(m, n)\}\)</support>
	<pdf>\(f(x) = \frac{{m \choose x} {N-m \choose n-x}}{{N \choose n}}, \; x \in \{\max(0, n + m - N), \ldots, \min(m, n)\}\)</pdf>
	<mode>\(\lfloor \frac{(n+1)(m+1)}{N+2} \rfloor\)</mode>
	<cdf>\(F(x) = \sum_{\max(0, n+m-N)}^x f(t), \quad x \in \{\max(0, n + m - N), \ldots, \min(m, n)\}\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(n \frac{m}{N}\)</mean>
	<variance>\(n \frac{m}{N} \frac{N - m}{N} \frac{N - n}{N - 1}\)</variance>
	<skew>\(\frac{(N - 2 m)(N - 2 n)}{n m (N - m)(N - 2)} \sqrt{\frac{N - 1}{N - 2}}\)</skew>
	<kurt>\(\left[ \frac{N^2 (N-1)}{n(N - 2)(N - 3)(N - n)}\right] \left[ \frac{N(N+1) - 6 N(N - n)}{m (N - m)} + \frac{3 n (N - n)(N + 6)}{N^2} - 6 \right]\)</kurt>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The hypergeometric distribution is very old, and was used by Jacob Bernoulli, Abraham DeMoivre, and others. The named was coined by H.T. Gonin in 1936.</history>
</distribution>

<distribution id="hyperbolic-secant">
	<name>hyperbolic secant distribution</name>
	<type>continuous</type>
	<model>The hyperbolic secant distribution is a symmetric, unimodal distribution but with larger kurtosis than the normal distribution.</model>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{2} \sech\left(\frac{\pi}{2} x\right), \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = \frac{2}{\pi} \arctan\left[\exp\left(\frac{\pi}{2} x \right)\right], \; x \in (-\infty, \infty)\)</cdf>
	<qf>\(Q(p) = \frac{2}{\pi} \ln[\tan(\frac{\pi}{2} p)], \; p \in (0, 1)\)</qf>
	<mgf>\(M(t) = \sec(t), \; t \in (-\frac{\pi}{1}, \frac{\pi}{2})\)</mgf>
	<cf>\(\varphi(t) = \sech(t), \; t \in (-\infty, \infty)\)</cf>
	<mean>\(0\)</mean>
	<variance>\(1\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(2\)</kurt>
	<entropy>\(\frac{4}{\pi \kappa}\) where \(\kappa\) is Catalan's constant</entropy>
	<median>\(0\)</median>
	<q1>\(\frac{2}{\pi} \ln(\sqrt{2} - 1)\)</q1>
	<q3>\(\frac{2}{\pi} \ln(\sqrt{2} + 1)\)</q3>
</distribution>

<distribution id="Irwin-Hall">
	<name>Irwin-Hall distribution</name>
	<type>continuous</type>
	<model>The Irwin-Hall distribution governs the sum of \(n\) independent variables, each uniformly distributed on \([0, 1]\).</model>
	<parameter>\(n \in \{1, 2, \ldots\}\), the number of terms</parameter>
	<support>\([0, n]\)</support>
	<pdf>\(f(x) = \frac{1}{2 (n - 1)!} \sum_{k=0}^n (-1)^k {n \choose k} (x - k)^{n-1} \sgn(x - k), \; x \in [0, n]\)</pdf>
	<mode>\(\frac{n}{2}\)</mode>
	<cdf>\(F(x) = \int_0^x f(t) dt, \quad x \in [0, n]\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>\(M(t) = \left(\frac{e^t - 1}{t}\right)^n, \; t \in (-\infty, \infty)\)</mgf>
	<moments> \(m(t) = \)</moments>
	<mean>\(\frac{n}{2}\)</mean>
	<variance>\(\frac{n^2}{12}\)</variance>
	<median>\(\frac{n}{2}\)</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The Irwin-Hall distribution is named for Joseph Irwin and Phillip Hall who independently analyzed the distribution in 1927.</history>
</distribution>

<distribution id="inverted-beta"> 
	<name>inverted beta distribution </name>
	<name>beta prime distribution </name>
	<name>beta distribution of the second kind</name>
	<type>continuous</type>
	<model>The inverted beta distribution is conjugate for the odds in the Bernoulli distribution </model>
	<parameter>\(\alpha \in (0, \infty)\), the first shape parameter</parameter>
	<parameter>\(\beta \in (0, \infty)\), the second shape parameter</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{B(\alpha, \beta)} x^{\alpha - 1} (1 + x)^{-(\alpha + \beta)}, \; x \in (0, \infty)\)</pdf>
	<mode>\(\frac{\alpha - 1}{\beta + 1}\) if \(\alpha \in [1, \infty)\)</mode>
	<cdf>\(F(x) = \int_0^x f(t) dt, \; x \in (0, \infty)\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(\frac{\alpha}{\beta - 1}\) if \(\beta \in (1, \infty)\)</mean>
	<variance>\(\frac{\alpha (\alpha + \beta - 1)}{(\beta - 2)(\beta - 1)^2}\) if \(\beta \in (2, \infty)\)</variance>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
</distribution>

<distribution id="Laplace">
	<name>Laplace distribution </name>
	<name>double exponential distribution</name>
	<type>continuous</type>
	<model>The Laplace distribution is a symmetric, unimodal distribution with tails that are fatter than those of the normal distribution </model>
	<parameter>\(\mu \in (-\infty, \infty)\), location</parameter>
	<parameter>\(b \in (0, \infty)\), scale</parameter>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{2 b} \exp\left(-\frac{|x - \mu|}{b}\right), \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(\mu\)</mode>
	<cdf>\(F(x) = \frac{1}{2} \exp\left(\frac{x - \mu}{b}\right), \; x \in (-\infty, \mu]; \quad F(x) = 1 - \frac{1}{2} \exp\left(-\frac{x - \mu}{b}\right), \; x \in [\mu, \infty)\)</cdf>
	<qf>\(Q(p) = \mu + b \ln(2 \min\{p, 1 - p\}), \; p \in (0, 1)\)</qf>
	<mgf>\(M(t) = \frac{e^{\mu t}}{1 - b^2 t}, \; t \in (-\frac{1}{b}, \frac{1}{b})\)</mgf>
	<cf>\(\varphi(t) = \frac{e^{\mu i t}}{1 + b^2 t}, \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\mu\)</mean>
	<variance>\(2 b^2\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(3\)</kurt>
	<entropy>\(\log(2 e b)\)</entropy>
	<median>\(\mu\)</median>
	<q1>\(\mu - b \ln(2)\)</q1>
	<q3>\(\mu + b \ln(2)\)</q3>
	<family>location </family>
	<family>scale</family>
	<history>The Laplace distribution is named for Pierre Simon Laplace.</history>
</distribution>

<distribution id="Levy">
	<name>Levy distribution </name>
	<name>van der Waals profile</name>
	<type>continuous</type>
	<model>The Levy distribution is a stable distribution that has applications in spectroscopy. </model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(c \in (0, \infty)\), the scale parameter</parameter>
	<support>\((\mu, \infty)\)</support>
	<pdf>\(f(x) = \sqrt{\frac{c}{2 \pi}} \frac{e^{-c/2(x - \mu)}}{(x - \mu)^{3/2}}, \; x \in (\mu, \infty)\)</pdf>
	<mode>\(\mu + \frac{c}{3}\)</mode>
	<cdf>\(F(x) = \int_\mu^x f(t) dt, \; x \in \) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<cf>\(\varphi(t) = \exp(i \mu t - \sqrt{-2 i c t}), \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\infty\)</mean>
	<variance>undefined</variance>
	<skew>undefined</skew>
	<kurt>undefined</kurt>
	<entropy>\(\frac{1}{2}[1 + 3 \gamma + \ln(16 \pi c^2)]\) where \(\gamma\) is Euler's constant</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>location </family>
	<family>scale </family>
	<family>stable</family>
	<history>The Levy distribution is named for Paul Pierre Levy.</history>
</distribution>

<distribution id="logarithmic">
	<name>logarithmic distribution </name>
	<name>logarithmic series distribution </name>
	<name>log-series distribution</name>
	<type>discrete</type>
	<model>The logarithmic distribution is sometimes used to model relative species abundance.</model>
	<parameter>\(p \in (0, 1)\), the shape parameter</parameter>
	<support>\(\{1, 2, \ldots\}\)</support>
	<pdf>\(f(x) = \frac{-1}{\ln(1 - p)} \frac{p^x}{x}, \; x \in \{1, 2, \ldots\}\)</pdf>
	<mode>\(1\)</mode>
	<cdf>\(F(x) = \sum_1^x f(t), \quad x \in \{1, 2, \ldots\}\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<pgf>\(G(t) = \frac{\ln(1 - p t)}{\ln(1 - p)}, \; t \in (-\frac{1}{p}, \frac{1}{p})\)</pgf>
	<mgf>\(M(t) = \frac{\ln(1 - p e^t)}{\ln(1 - p)}, \; t \in (-\infty, -\ln(p))\)</mgf>
	<cf>\(\varphi(t) = \frac{\ln(1 - p e^{i t})}{\ln(1 - p)}, \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\frac{-1}{\ln(1 - p)} \frac{p}{1 - p}\)</mean>
	<variance>\(-\frac{\ln(1 - p)}{\ln^2(1 - p)} \left(\frac{p}{1 - p}\right)^2\)</variance>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>power series</family>
	<history>The logarithmic distribution was first derived by Ronald Fisher in 1943.</history>
</distribution>

<distribution id="logistic">
	<name>logistic distribution</name>
	<type>continuous</type>
	<model>The logistic distribution occurs in logistic regression.</model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(b \in (0, \infty)\), the scale parameter</parameter>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{\exp\left[-\left(\frac{x - \mu}{b}\right)\right]}{b\left\{1 + \exp\left[-\left(\frac{x - \mu}{b}\right)\right]\right\}^2}, \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(\mu\)</mode>
	<cdf>\(F(x) = \frac{1}{1 + \exp\left[-\left(\frac{x - \mu}{b}\right)\right]}, \; x \in (-\infty, \infty)\)</cdf>
	<qf>\(Q(p) = \mu + b \ln\left(\frac{p}{1 - p}\right), \; p \in (0, 1)\)</qf>
	<mgf>\(M(t) = e^{\mu t} B(1 - b t, 1 + b t)\) where \(B\) is the beta function</mgf>
	<mean>\(\mu\)</mean>
	<variance>\(\frac{\pi^2}{3} b^2\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(\frac{6}{5}\)</kurt>
	<entropy>\(\ln(b) + 2\)</entropy>
	<median>\(\mu\)</median>
	<q1>\(\mu - \ln(3) b\)</q1>
	<q3>\(\mu + \ln(3) b\)</q3>
	<family>location </family>
	<family>scale</family>
	<history>Logistic regression was first used by D.R. Cox in 1958.</history>
</distribution>

<distribution id="log-normal">
	<name>log-normal distribution </name>
	<name>log normal distribution </name>
	<name>lognormal distribution </name>
	<name>Galton distribution</name>
	<type>continuous</type>
	<model>The log-normal distribution models certain skewed variables.</model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(\sigma \in (0, \infty)\), the scale parameter</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{x \sqrt{2 \pi \sigma^2}} \exp\left[-\frac{1}{2}\left(\frac{ln(x) - \mu}{\sigma}\right)^2\right], \; x \in (0, \infty)\)</pdf>
	<mode>\(e^{\mu - \sigma^2}\)</mode>
	<cdf>\(F(x) = \Phi \left(\frac{ln(x) - \mu}{\sigma}\right), \; x \in (0, \infty)\) where \(\Phi\) is the standard normal distribution function</cdf>
	<qf>\(Q(p) = \exp\left(\mu + \sigma \Phi^{-1}(p)\right)\), where \(\Phi\) is the standard normal distribution function</qf>
	<moments type="raw">\(\mu(n) = \exp(\mu n + \frac{1}{2} \sigma^2 n^2), \; n \in \{0, 1, \ldots\}\)</moments>
	<mean>\(\exp(\mu + \frac{1}{2} \sigma^2)\)</mean>
	<variance>\(\exp\left(2 (\mu + \sigma^2)\right) - \exp(2 \mu + \sigma^2)\)</variance>
	<skew>\(\left(e^{\sigma^2} - 2\right) \sqrt{e^{\sigma^2} - 1}\)</skew>
	<kurt>\(e^{4 \sigma^2} + 2 e^{3 \sigma^2} + 3 e^{2 \sigma^2} - 6\)</kurt>
	<entropy>\(\frac{1}{2}[1 + \ln(2 \pi \sigma^2)] + \mu\)</entropy>
	<median>\(e^\mu\)</median>
	<q1>\(\exp\left(\mu + \sigma \Phi^{-1}(\frac{1}{4})\right)\), where \(\Phi\) is the standard normal distribution function</q1>
	<q3>\(\exp\left(\mu + \sigma \Phi^{-1}(\frac{3}{4})\right)\), where \(\Phi\) is the standard normal distribution function</q3>
	<family>scale </family>
	<family>exponential</family>
	<history>The lognormal distribution was first studied by Donald McAlister in 1879, in response to a problem posed by Francis Galton. This historical origin is the reason for the alternative name Galton distribution. The term lognormal distribution was first used by J.H. Gaddum in 1945.</history>
</distribution>

<distribution id="log-logistic">
	<name>log-logistic distribution </name>
	<name>Fisk distribution</name>
	<type>continuous</type>
	<model>The log-logistic distribution models lifetimes of devices whose failure rates at first increase and then decrease.</model>
	<parameter>\(\alpha \in (0, \infty)\), the scale parameter</parameter>
	<parameter>\(\beta \in (0, \infty)\), the shape parameter</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = \frac{\beta}{\alpha} \frac{(x/\alpha)^{\beta-1}}{[1 + (x/\alpha)^\beta]^2}, \; x \in (0, \infty)\)</pdf>
	<mode>\(0\) if \(\beta = 1\); \quad \(\alpha \left(\frac{\beta - 1}{\beta + 1}\right)^{1/\beta}\) if \(\beta \in (1, \infty)\)</mode>
	<cdf>\(F(x) = \frac{1}{1 + (x/\alpha)^{-\beta}}, \; x \in (0, \infty)\)</cdf>
	<qf>\(Q(p) = \alpha \left(\frac{p}{1 - p}\right)^{1/\beta}, \; p \in (0, 1)\)</qf>
	<moments type="raw">\(\mu(n) = \alpha^n \frac{n \pi /\beta}{\sin(n \pi / \beta)}, \; n \lt \beta\)</moments>
	<mean>\(\frac{\alpha \pi / \beta}{\sin(\pi / \beta)}\) if \(\beta \in (1, \infty)\)</mean>
	<variance>\(\alpha^2 \left[\frac{2 \pi / \beta}{\sin(2 \pi / \beta)} - \frac{(\pi / \beta)^2}{\sin^2(\pi / \beta)}\right]\) if \(\beta \in (2, \infty)\)</variance>
	<median>\(\alpha\)</median>
	<q1>\(\alpha \left(\frac{1}{3}\right)^{1/\beta}\)</q1>
	<q3>\(\alpha 3^{1/\beta}\)</q3>
	<family>scale</family>
	<history>The log-logistic distribution is known as the Fisk distribution by economists. P.R. Fisk used the distribution to model income in 1961.</history>
</distribution>

<distribution id="Maxwell-Boltzman">
	<name>Maxwell-Boltzmann distribution</name>
	<type>continuous</type>
	<model>The Maxwell-Boltzmann Distribution arises in the kinetic theory of gases.</model>
	<parameter>\(a \in (0, \infty)\), the scale parameter</parameter>
	<support>\([0, \infty)\)</support>
	<pdf>\(f(x) = \sqrt{\frac{2}{\pi}} \frac{1}{a^3} x^2 e^{-x^2/2 a}, \; x \in [0, \infty)\)</pdf>
	<mode>\(\sqrt{2} a\)</mode>
	<cdf>\(F(x) = \int_a^x f(t) dt, \; x \in \) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(2 a \sqrt{\frac{2}{\pi}}\)</mean>
	<variance>\(a^2 \frac{3 \pi - 8}{\pi}\)</variance>
	<skew>\(\frac{2 \sqrt{2}(16 - 5 \pi)}{(3 \pi - 8)^{3/2}}\)</skew>
	<kurt>\(4 \frac{-96 + 40 \pi - 3\pi^2}{(3 \pi - 8)^2}\)</kurt>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>scale</family>
	<history>The Maxwell-Boltzman distribution is named for James Clerk Maxwell and Ludwig Boltzmann for their use of the distribution is modeling the energy of molecules in a gas.</history>
</distribution>

<distribution id="negative-binomial">
	<name>negative binomial distribution </name>
	<name>Pascal distribution</name>
	<type>discrete</type>
	<model>The negative binomial distribution governs the number of trials needed for a specified number of successes in the Bernoulli trials model.</model>
	<parameter>\(k \in \{1, 2, \ldots\}\), the number of successes</parameter>
	<parameter>\(p \in (0, 1]\), the success parameter</parameter>
	<support>\(\{k, k+1, \ldots\}\)</support>
	<pdf>\(f(x) = {x-1 \choose k-1} p^x (1 - p)^{x-k}, \; x \in \{k, k+1, \ldots\}\)</pdf>
	<mode>\(\lfloor 1 + \frac{k-1}{p}\rfloor\)</mode>
	<cdf>\(F(x) = \sum_{j=k}^x f(j) , \; x \in \{k, k+1, \ldots\}\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<pgf>\(G(t) = \left[\frac{p t}{1 - (1-p) t}\right]^k, \; t \in (-\frac{1}{1-p}, \frac{1}{1-p})\)</pgf>
	<mgf>\(M(t) = \left[\frac{p e^t}{1 - (1-p) e^t}\right]^k, \; t \in (-\infty, -\ln(1 - p))\)</mgf>
	<cf>\(\varphi(t) = \left[\frac{p e^{i t}}{1 - (1-p) e^{i t}}\right]^k, \; t\in (-\infty, \infty)\)</cf>
	<mean>\(k \frac{1}{p}\)</mean>
	<variance>\(k \frac{1-p}{p^2}\)</variance>
	<skew>\(\frac{2-p}{\sqrt{k (1-p)}}\)</skew>
	<kurt>\(\frac{1}{k} \left[6 + \frac{p^2}{1 - p}\right]\)</kurt>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The alternative name Pascal distribution is in honor of Blaise Pascal who used the distribution in his solution to the Problem of Points.</history>
</distribution>

<distribution id="normal">
	<name>normal distribution </name>
	<name>Gaussian distribution </name>
	<name>error distribution</name>
	<type>continuous</type>
	<model>The normal distribution is used to model physical quantities that are subject to numerous small, random errors.</model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(\sigma \in (0, \infty)\), the scale parameter</parameter>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{1}{2}(\frac{x - \mu}{\sigma})^2 \right), \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(\mu\)</mode>
	<cdf>\(F(x) = \Phi\left(\frac{x - \mu}{\sigma}\right), \; x \in (-\infty, \infty)\) where \(\Phi\) is the standard normal distribution function</cdf>
	<qf>\(Q(p) =  \mu + \sigma \Phi^{-1}(p), \; p \in (0, 1)\) where \(\Phi\) is the standard normal distribution function</qf>
	<mgf>\(M(t) = \exp(\mu t + \frac{1}{2} \sigma^2 t^2), \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = \exp(i \mu t - \frac{1}{2} \sigma^2 t^2), \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\mu\)</mean>
	<variance>\(\sigma^2\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(0\)</kurt>
	<entropy>\(\frac{1}{2} \ln(2 \pi e \sigma^2)\)</entropy>
	<median>\(\mu\)</median>
	<q1>\(\mu - \Phi^{-1}(\frac{1}{4}) \sigma\) where \(\Phi\) is the standard normal distribution function</q1>
	<q3>\(\mu + \Phi^{-1}(\frac{1}{4}) \sigma\) where \(\Phi\) is the standard normal distribution function</q3>
	<family>location </family>
	<family>scale </family>
	<family>exponential </family>
	<family>stable</family>
	<cite>Dinov Christou Sanchez 2008</cite>
	<history>The normal distribution was first derived by Carl Friedrich Gauss in 1809 (hence the alternative name Gaussian distribution). The normalizing constant and the first version of the Central Limit Theorem were contributions by Pierre Simon Laplace. The term <q>normalizing constant</q> was popularized by Karl Pearson around the turn of the 20th century.</history>
</distribution>

<distribution id="Pareto">
	<name>Pareto distribution </name>
	<name>Bradford distribution</name>
	<type>continuous</type>
	<model>The Pareto distribution models highly skewed variables that sometimes arise in economics.</model>
	<parameter>\(k \in (0, \infty)\), the shape parameter</parameter>
	<parameter>\(a \in (0, \infty)\), the scale parameter</parameter>
	<support>\([a, \infty)\)</support>
	<pdf>\(f(x) = \frac{k a^k}{x^{k+1}}, \; x \in [a, \infty)\)</pdf>
	<mode>\(a\)</mode>
	<cdf>\(F(x) = 1 - \left(\frac{a}{x}\right)^a, \; x \in [a, \infty)\)</cdf>
	<qf>\(Q(p) = \frac{a}{(1 - p)^{1/k}}, \; p \in [0, 1)\) where \(F\)</qf>
	<mgf>Does not exist</mgf>
	<cf>\(\varphi(t) = k (-i a t)^k \gamma(-k, -i a t)\) where \(\gamma\) is the lower incomplete gamma function</cf>
	<moments type="raw">\(\mu(t) = a^t \frac{k}{k - t}, \; t \in (0, k)\)</moments>
	<mean>\(a \frac{k}{k - 1}\)</mean>
	<variance>\(a^2 \frac{k}{(k - 1)^2 (k - 2)}\)</variance>
	<skew>\(\frac{2 (1 + k)}{k - 3} \sqrt{\frac{k - 2}{k}}, \; k \in (3, \infty)\)</skew>
	<kurt>\(\frac{6 (k^3 + k^2 - 6 k - 2}{k (k - 3) (k - 4)}\)</kurt>
	<entropy>\(\ln\left(\frac{k}{a}\right) - \frac{1}{k} - 1\)</entropy>
	<median>\(a 2^{1/k}\)</median>
	<q1>\(a (\frac{4}{3})^{1/k}\)</q1>
	<q3>\(a 4 ^{1/k}\)</q3>
	<family>scale </family>
	<history>The Pareto distributin is named for the Italian economist Vilfredo Pareto, who used the distribution to model wealth, income and other economic variables. </history>
</distribution>
 
<distribution id="Poisson"> 
	<name>Poisson distribution</name>
	<type>discrete</type>
	<model>The Poisson distribution models the number of random points in a region of time or space under certain ideal conditions.</model>
	<parameter>\(\lambda \in (0, \infty)\), the shape parameter</parameter>
	<support>\(\{0, 1, 2, \ldots\}\)</support>
	<pdf>\(f(x) = e^{-\lambda} \frac{\lambda^k}{k!}, \; k \in \{0, 1, 2, \ldots\}\)</pdf>
	<mode>\(\lfloor \lambda \rfloor\)</mode>
	<cdf>\(F(x) = \frac{\gamma(x + 1, \lambda)}{x!}, \; x \in \{0, 1, 2, \ldots\}\) where \(\gamma\) is the lower incomplete gamma function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<pgf>\(G(t) = e^{\lambda (t - 1)}, \; t \in (-\infty, \infty)\)</pgf>
	<mgf>\(M(t) = \exp(\lambda(e^t - 1)), \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = \exp(\lambda(e^{i t} - 1)), \; t \in (-\infty, \infty)\)</cf>
	<moments type="factorial">\(m(k) = \lambda^k, \; k \in \{0, 1, 2, \ldots\}\)</moments>
	<mean>\(\lambda\)</mean>
	<variance>\(\lambda\)</variance>
	<skew>\(\sqrt{\lambda}\)</skew>
	<kurt>\(\frac{1}{\lambda}\)</kurt>
	<entropy>\(\lambda [1 - \log(\lambda)] + e^{-\lambda} \sum_{k=0}^\infty \frac{\lambda^k \log(k!)}{k!}\)</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>exponential </family>
	<family>power series</family>
	<history>The Poisson distribution is named for Simeon Poisson who first used the distribution in 1838 in a study of judgements in court cases.</history>
</distribution>

<distribution id="Rademacher">
	<name>Rademacher distribution</name>
	<type>discrete</type>
	<model>The Rademacher distribution arises in physics and in bootstrapping.</model>
	<support>\(\{-1, 1\}\)</support>
	<pdf>\(f(x) = \frac{1}{2}, \; x \in \{-1, 1\}\)</pdf>
	<mode>\(\{-1, 1\}\)</mode>
	<cdf>\(F(-1) = \frac{1}{2}, \; F(1) = 1\)</cdf>
	<qf>\(Q(p) = -1, \; p \in [0, \frac{1}{2}]; \quad Q(p) = 1, \; p \in (\frac{1}{2}, 1]\)</qf>
	<mgf>\(M(t) = \cosh(t), \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(M(t) = \cos(t), \; t \in (-\infty, \infty)\)</cf>
	<moments type="raw">\(\mu(n) = 1, \; n \in \{0, 2, \ldots\}; \quad \mu(n) = 0, \; n \in \{1, 3, \ldots\}\)</moments>
	<mean>\(0\)</mean>
	<variance>\(1\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(-2\)</kurt>
	<entropy>\(\ln(2)\)</entropy>
	<median>\(0\)</median>
	<q1>\(-1\)</q1>
	<q3>\(1\)</q3>
	<history>The Rademacher distribution is named for the German mathematician Hans Rademacher.</history>
</distribution>

<distribution id="Rayleigh">
	<name>Rayleigh distribution</name>
	<type>continuous</type>
	<model>The Rayleigh distribution governs the magnitude of a vector with independent, normal components that have zero mean and the same variance.</model>
	<parameter>\(\sigma \in (0, \infty)\), scale</parameter>
	<support>\([0, \infty)\)</support>
	<pdf>\(f(x) = \frac{x}{\sigma^2} \exp\left(-\frac{x^2}{2 \sigma^2}\right), \; x \in [0, \infty)\)</pdf>
	<mode>\(\sigma\)</mode>
	<cdf>\(F(x) = 1 - \exp\left(-\frac{x^2}{2 \sigma^2}\right)\)</cdf>
	<qf>\(Q(p) = \sigma \sqrt{-2 \ln(1 - p)}, \; p \in [0, 1)\)</qf>
	<mgf>\(M(t) = 1 + \sqrt{\frac{\pi}{2}}\sigma t \exp\left(\frac{1}{2} \sigma^2 t^2\right)\left[\erf\left(\frac{1}{\sqrt{2}} t \right) + 1\right], \; t \in (-\infty, \infty)\) where \(\erf\) is the error function</mgf>
	<moments type="raw">\(\mu(t) = \Gamma\left(1 + \frac{t}{2}\right), \; t \in [0, \infty)\)</moments>
	<mean>\(\sigma \sqrt{\frac{\pi}{2}}\)</mean>
	<variance>\(\frac{4 - \pi}{2} \sigma^2\)</variance>
	<skew>\(\frac{2 \sqrt{\pi} (\pi - 3)}{(4 - \pi)^{3/2}}\)</skew>
	<kurt>\(-\frac{6 \pi^2 - 24 \pi + 16}{(4 - \pi)^{3/2}}\)</kurt>
	<entropy>\(1 + \ln\left(\frac{\sigma}{\sqrt{2}}\right) + \frac{\gamma}{2}\) where \(\gamma\) is Euler's constant</entropy>
	<median>\(\sigma \sqrt{\ln(4)}\)</median>
	<q1>\(\sigma \sqrt{\ln(16) - \ln(9)}\)</q1>
	<q3>\(\sigma \sqrt{\ln(16)}\)</q3>
	<family>scale</family>
	<history>The Rayleigh distribution is named for the English mathematician Lord Rayleigh (John William Strutt).</history>
</distribution>

<distribution id="Rice">
	<name>Rice distribution </name>
	<name>Rician distribution</name>
	<type>continuous</type>
	<model>The Rice distribution governs the magnitude of a circular bivariate normal random vector.</model>
	<parameter>\(\nu \in [0, \infty)\), the distance parameter</parameter>
	<parameter>\(\sigma \in (0, \infty)\), the scale parameter</parameter>
	<support>\([0, \infty)\)</support>
	<pdf>\(f(x) = \frac{x}{\sigma^2} \exp\left[-\frac{(x^2 + \nu^2)}{2 \sigma^2} \right] I_0\left(\frac{x \nu}{\sigma^2}\right), \; x \in [0, \infty)\) where \(I_0\) is the modified Bessel function.</pdf>
	<cdf>\(F(x) = 1 - Q\left(\frac{\nu}{\sigma}, \frac{x}{\sigma}\right), \; x \in [0, \infty)\) where \(Q\) is the Marcum \(Q\)-function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(\sigma \sqrt{\frac{\pi}{2}} L_{1/2}\left(-\frac{\nu^2}{2 \sigma^2}\right)\) where \(L_{1/2}\) is the Laguerre polynomial of order \(1/2\).</mean>
	<variance>\(2 \sigma^2 + \nu^2 - \frac{\pi \sigma^2}{2} L^2_{1/2}\left(-\frac{\nu^2}{2 \sigma^2}\right)\) where \(L_{1/2}\) is the Laguerre polynomial of order \(1/2\).</variance>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>scale</family>
	<history>The Rice distribution is named for Stephen O. Rice who used the distribution in 1945 in his study of random noise.</history>
</distribution>

<distribution id="semicircle">
	<name>semicircle distribution </name>
	<name>Wigner distribution </name>
	<name>Stato-Tate distribution</name>
	<type>continuous</type>
	<model>The semicircle distribution arises as the limiting distribution of the eigenvalues of random symmetric matrices.</model>
	<parameter>\(r \in (0, \infty)\), the radius</parameter>
	<support>\([-r, r]\)</support>
	<pdf>\(f(x) = \frac{2}{\pi r^2} \sqrt{r^2 - x^2}, \; x \in [-r, r]\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = \frac{1}{2} + \frac{1}{\pi r^2} x \sqrt{r^2 - x^2} + \frac{1}{\pi} \arcsin\left(\frac{x}{r}\right), \; x \in [-r, r]\)</cdf>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>\(M(t) = 2 \frac{I_1(r t)}{r t}, \; t \in (-\infty, \infty)\) where \(I_1\) is the modified Bessel function</mgf>
	<cf>\(\varphi(t) = 2 \frac{J_1(r t)}{r t}, \; t \in (-\infty, \infty)\) where \(J_1\) is the Bessel function</cf>
	<moments type="raw">\(\mu(n) = 0, \; n \in \{1, 3, \ldots\}; \quad \mu(n) = \frac{1}{n + 1} {2 n \choose n}, \; n \in \{0, 2, \ldots\} \)</moments>
	<mean>\(0\)</mean>
	<variance>\(\frac{r^2}{4}\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(-1\)</kurt>
	<entropy>\(\ln(\pi r) - \frac{1}{2}\)</entropy>
	<median>\(0\)</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>scale</family>
	<history>The semicircle distribution was used by the physicist Eugene Wigner in the study of random matrices. The distribution was also used by Nikio Sato and John Tate in a conjecture in number theory.</history>
</distribution>

<distribution id="standard-Cauchy">
	<name>standard Cauchy distribution</name>
	<type>continuous</type>
	<model>The standard Cauchy distribution governs the ratio of two independent, standard normal variables.</model>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{\pi (1 + x^2)}, \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(t) = \frac{1}{2} + \frac{1}{\pi} \arctan(x), \; x \in (-\infty, \infty)\)</cdf>
	<qf>\(Q(p) = \tan(\pi (p - \frac{1}{2})), \; p \in (0, 1)\)</qf>
	<mgf>Does not exist</mgf>
	<cf>\(\varphi(t) = e^{-|t|}\)</cf>
	<mean>Does not exist</mean>
	<variance>Does not exist</variance>
	<skew>Does not exist</skew>
	<kurt>Does not exist</kurt>
	<entropy>\(\ln( 4 \pi)\)</entropy>
	<median>\(0\)</median>
	<q1>\(-1\)</q1>
	<q3>\(1\)</q3>
</distribution>

<distribution id="Gumbel-standard">
	<name>standard Gumbel distribution</name>
	<type>continuous</type>
	<model>The standard Gumbel distribution models the limit of of the maximum of independent, identically distributed variables.</model>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = e^{-x} e^{-e^{-x}}, \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = e^{-e^{-x}}, \; x \in (-\infty, \infty)\)</cdf>
	<qf>\(Q(p) = -\ln(-\ln(p)), \; p \in (0, 1)\)</qf>
	<mgf>\(M(t) = \Gamma(1 - t), \; t \in (-\infty, 1)\)</mgf>
	<mean>\(\gamma\) where \(\gamma\) is Euler's constant</mean>
	<variance>\(\frac{\pi^2}{6}\)</variance>
	<skew>\(\frac{12 \sqrt{6}}{\pi^2} \zeta(3)\) where \(\zeta\) is the zeta function</skew>
	<kurt>\(\frac{12}{5}\)</kurt>
	<entropy>\(\gamma + 1\) where \(\gamma\) is Euler's constant</entropy>
	<median>\(-\ln(\ln(2))\)</median>
	<q1>\(-\ln(\ln(4) - \ln(3))\)</q1>
	<q3>\(-\ln(\ln(4))\)</q3>
</distribution>

<distribution id="logistic-stanadard">
	<name>standard logistic distribution</name>
	<type>continuous</type>
	<model>The standard logistic distribution arises in logistic regression</model>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{e^x}{(1 + e^x)^2}, \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = \frac{e^x}{1 + e^x}, \; x \in (-\infty, \infty)\)</cdf>
	<qf>\(Q(p) = \ln\left(\frac{p}{1 - p}\right), \; p \in (0, 1)\)</qf>
	<mgf>\(M(t) = B(1 - t, 1 + t), \; t \in (-\infty, \infty)\) where \(B\) is the beta function</mgf>
	<mean>\(0\)</mean>
	<variance>\(\frac{\pi^2}{3}\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(\frac{6}{5}\)</kurt>
	<entropy>\(\ln(2)\)</entropy>
	<median>\(0\)</median>
	<q1>\(-\ln(3)\)</q1>
	<q3>\(\ln(3)\)</q3>
</distribution>

<distribution id="standard-normal">
	<name>standard normal distribution</name>
	<type>continuous</type>
	<model>The standard normal distribution models standardized physical quantities subject to numerous small, random errors.</model>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{\sqrt{2 \pi}} \exp\left(-\frac{1}{2} x^2\right), \; x \in (-\infty, \infty)\)</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = \int_{-\infty}^x f(t) dt, \; x \in (-\infty, \infty)\) where \(f\) is the density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>\(M(t) = \exp(\frac{1}{2} t^2), \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = \exp(-\frac{1}{2} t^2), \; t \in (-\infty, \infty)\)</cf>
	<mean> \(0\)</mean>
	<variance>\(1\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(0\)</kurt>
	<entropy>\(\frac{1}{2} \ln(2 \pi)\)</entropy>
	<median>\(0\)</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The term <q>standard normal distribution</q> came into general use around 1950.</history>
</distribution>

<distribution id="standard-uniform">
	<name>standard uniform distribution</name>
	<type>continuous</type>
	<model>The standard uniform distribution models a point chosen at random from the interval \([0, 1]\).</model>
	<support>\([0, 1]\)</support>
	<pdf>\(f(x) = 1, \; x \in [0, 1]\)</pdf>
	<mode>\(F(x) = x, \; x \in [0, 1]\)</mode>
	<cdf>\(F(x) = \int_a^x f(t) dt, \quad x \in \) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = p, \quad p \in [0, 1]\)</qf>
	<mgf>\(M(t) = \frac{e^t - 1}{t}, \; t \in (-\infty, \infty)\)</mgf>
	<cf>\(\varphi(t) = \frac{e^{i t} - 1}{it}, \; t \in (-\infty, \infty)\)</cf>
	<moments type="raw">\(\mu(n) = \frac{1}{n+1}, \; n \in {0, 1, \ldots}\)</moments>
	<mean>\(\frac{1}{2}\)</mean>
	<variance>\(\frac{1}{12}\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(-\frac{6}{5}\)</kurt>
	<entropy>\(0\)</entropy>
	<median>\(\frac{1}{2}\)</median>
	<q1>\(\frac{1}{4}\)</q1>
	<q3>\(\frac{3}{4}\)</q3>
</distribution>

<distribution id="student">
	<name>t-distribution </name>
	<name>Student t-distribution</name>
	<type>continuous</type>
	<model>The Student t-distribution arises in a sample from a normal distribution, when the sample mean is standardized using the sample standard deviation </model>
	<parameter>\(n \in (0, \infty)\), degrees of freedom</parameter>
	<support>\((-\infty, \infty)\)</support>
	<pdf>\(f(x) = \frac{\Gamma((n+1)/2)}{\sqrt{n \pi} \Gamma(n/2)} \left( 1 + \frac{x^2}{n} \right)^{-(n+1)/2}, \; x \in (-\infty, \infty)\) where \(\Gamma\) is the gamma function</pdf>
	<mode>\(0\)</mode>
	<cdf>\(F(x) = \frac{B(x; n/2, n/2)}{B(n/2, n/2)}\) where \(B\) is the beta function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>Does not exist</mgf>
	<cf>\(\frac{K_{n/2}(\sqrt{n} |t|) (\sqrt{n} |t|)^{n/2}}{\Gamma(n/2) 2^{n/2-1}}, \; t -in (-\infty, \infty)\) where \(K_n\) is the Bessel function and \(\Gamma\) is the gamma function</cf>
	<mean>\(0, \; n \in (1, \infty)\)</mean>
	<variance>\(\frac{n}{n-2}, \; n \in (2, \infty)\)</variance>
	<skew>\(0, \; n \in (3, \infty)\)</skew>
	<kurt>\(\frac{12}{n}\)</kurt>
	<entropy>\(\frac{n}{2} + \ln(2 \Gamma(\frac{n}{2})) + (1 - \frac{k}{2}) \psi(\frac{n}{2})\) where \(\psi\) is the digamma function</entropy>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The \(t\)-distribution was derived by William Sealy Gosset while he worked at the Guinness Brewery in Dublin.  Gosset published his work under the pseudonym <em>Student</em>. The \(t\)-test in statistics was developed by Ronald Fisher who called the distribution <q>Student's distribution</q></history>
</distribution>

<distribution id="triangular">
	<name>triangular distribution</name>
	<type>continuous</type>
	<model>The triangular distribution arises from various simple combinations of continuous uniform distributions.</model>
	<parameter>\(a \in (-\infty, \infty)\), the left endpoint</parameter>
	<parameter>\(b \in (a, \infty)\), the right endpoint</parameter>
	<parameter>\(c \in [a, b]\), the mode</parameter>
	<support>\([a, b]\)</support>
	<pdf>\(f(x) = \frac{2 (x - a)}{(b - a)(c - a)}, \; x \in [a, c]; \quad f(x) = \frac{2 (b - x)}{(b - a)(b - c)}, \; x \in [c, b]\)</pdf>
	<mode>\(c\)</mode>
	<cdf>\(F(x) = \frac{(x - a)^2}{(b - a)(c - a)}, \; x \in [a, c]; \quad F(x) = 1 - \frac{(b - x)^2}{(b - a)(b - c}, \; x \in [c, b]\)</cdf>
	<qf>\(Q(p) = a + \sqrt{(b - a)(c - a) p}, \; p \in \left[0, \frac{c - a}{b - a}\right]; \quad Q(p) = b - \sqrt{(1 - p)(b - a)(b - c)}, \; p \in \left[\frac{c - a}{b - a}, 1\right]\)</qf>
	<mgf>\(M(t) = 2 \frac{(b - c) e^{a t} - (b - a) e^{c t} + (c - a) e^{b t}}{(b - a)(c - a)(b - c) t^2}, \; t \in (-\infty, \infty)\)</mgf>
	<mean>\(\frac{a + b + c}{3}\)</mean>
	<variance>\(\frac{a^2 + b^2 + c^2 - a b - a c - b c}{18}\)</variance>
	<skew>\(\frac{\sqrt{2} (a + b - 2 c)(2 a - b - c)(a - 2 b + c)}{5(a^2 + b^2 + c^2 - a b - a c - b c)}\)</skew>
	<kurt>\(-\frac{3}{5}\)</kurt>
	<entropy>\(\frac{1}{2} + \ln\left(\frac{b - a}{2}\right)\)</entropy>
	<median>\(a + \sqrt{\frac{1}{2}(b - a)(c - a)}\) if \(c \geq \frac{a + b}{2}\); \(b - \sqrt{\frac{1}{2}(b - a)(b - c)}\) if \(c \leq \frac{a + b}{2}\)</median>
	<q1>\(a + \sqrt{\frac{1}{4}(b - a)(c - a)}\) if \(c \geq \frac{3}{4} a + \frac{1}{4} b\); \(b - \sqrt{\frac{3}{4}(b - a)(b - c)}\) if \(c \leq \frac{3}{4} a + \frac{1}{4} b\)</q1>
	<q3>\(a + \sqrt{\frac{3}{4}(b - a)(c - a)}\) if \(c \geq \frac{1}{4} a + \frac{3}{4} b\); \(b - \sqrt{\frac{1}{4}(b - a)(b - c)}\) if \(c \leq \frac{1}{4} a + \frac{3}{4} b\)</q3>
</distribution>

<distribution id="U-quadratic"> 
	<name>U-quadratic distribution</name>
	<type>continuous</type>
	<model>the U-quadratic distribution models certain symmetric, bimodal variables.</model>
	<parameter>\(a \in (-\infty, \infty)\), the left endpoint</parameter>
	<parameter>\(b \in (a, \infty)\), the right endpoint</parameter>
	<support>\([a, b]\)</support>
	<pdf>\(f(x) = \frac{12}{(b - a)^3} \left(x - \frac{a + b}{2}\right)^2, \; x \in [a, b]\)</pdf>
	<mode>\(\{a, b\}\)</mode>
	<cdf>\(F(x) = \frac{4}{(b - a)^3} \left[\left(x - \frac{a+b}{2}\right)^3 + \left(\frac{a+b}{2} - \frac{12}{(b - a)^3} \right)^3 \right], \; x \in [a, b]\)</cdf>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>\(M(t) = \frac{3 e^{a t}[4 + (a^2 + 2 a (b - 2) + b^2) t] - 3 e^{b t}[4 + ((a+b)^2 - 4 b) t]}{(b - a)^3 t^2}, \; t \in (-\infty, \infty)\)</mgf>
	<mean>\(\frac{a+b}{2}\)</mean>
	<variance>\(\frac{3}{20}(b - a)^3\)</variance>
	<skew>\(0\)</skew>
	<kurt>\(\frac{3}{112}(b - a)^4\)</kurt>
	<median>\(\frac{a+b}{2}\)</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
</distribution>

<distribution id="von-Mises">
	<name>von Mises distribution </name>
	<name>circular normal distribution</name>
	<name>Tikhanov distribution</name>
	<type>continuous</type>
	<model>The von Mises distribution is used as an approximation to the wrapped normal distribution </model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(\beta \in (0, \infty)\), the concentration parameter</parameter>
	<support>\([\mu - \pi, \mu + \pi]\)</support>
	<pdf>\(f(x) = \frac{1}{2 \pi I_0(\beta)} \exp[\beta \cos(x - \mu)], \; x \in [\mu - \pi, \mu + \pi]\)</pdf>
	<mode>\(\mu\)</mode>
	<cdf>\(F(x) = \int_{\mu - \pi} ^x f(t) dt, \; x \in [\mu - \pi, \mu + \pi]\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(\mu\)</mean>
	<variance>\(1 - \frac{I_1(\beta)}{I_0(\beta)}\), where \(I_n\) is the modified Bessel function of order \(n\)</variance>
	<skew>\(0\)</skew>
	<entropy>\(-\beta \frac{I_1(\beta)}{I_0(\beta)} + \ln[2 \pi I_0(\beta)]\) where \(I_n\) is the modfied Bessel function of order \(n\)</entropy>
	<median>\(\mu\)</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<family>location</family>
	<history>The von Mises distribution is named for Richard von Mises based on his work in diffusion processes.</history>
</distribution>

<distribution id="Wald">
	<name>Wald distribution </name>
	<name>inverse Gaussian distribution</name>
	<type>continuous</type>
	<model>The Wald distribution governs the time that Brownian Motion with positive drift reaches a fixed positive value.</model>
	<parameter>\(\mu \in (0, \infty)\), the mean</parameter>
	<parameter>\(\lambda \in (0, \infty)\), the shape parameter</parameter>
	<support>\((0, \infty)\)</support>
	<pdf>\(f(x) = \sqrt{\frac{\lambda}{2 \pi x^3}} \exp\left[-\frac{\lambda (x - \mu)^2}{2 \mu^2 x}\right], \; x \in (0, \infty)\)</pdf>
	<mode>\(\mu \left[ \sqrt{1 + \left(\frac{3 \mu}{2 \lambda}\right)^2} - \frac{3 \mu}{2 \lambda} \right]\)</mode>
	<cdf>\(F(x) = \Phi\left[\sqrt{\frac{\lambda}{x}} \left(\frac{x}{\mu} - 1\right)\right] + \exp\left(\frac{2 \lambda}{\mu}\right) \Phi\left[-\sqrt{\frac{\lambda}{x}} \left(\frac{x}{\mu} + 1\right)\right], \; x \in (0, \infty)\) where \(\Phi\) is the standard normal distribution function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<mgf>\(M(t) = \exp \left[ \frac{\lambda}{\mu} \left(1 - \sqrt{1 - \frac{2 \mu^2}{\lambda} t} \right)\right], \; t \in (-\infty, \frac{\lambda}{2 \mu^2})\)</mgf>
	<cf>\(\varphi(t) = \exp \left[ \frac{\lambda}{\mu} \left(1 - \sqrt{1 - \frac{2 \mu^2}{\lambda} i t} \right)\right], \; t \in (-\infty, \infty)\)</cf>
	<mean>\(\mu\)</mean>
	<variance>\(\frac{\mu^3}{\lambda}\)</variance>
	<skew>\(3 \sqrt{\frac{\mu}{\lambda}}\)</skew>
	<kurt>\(15 \frac{\mu}{\lambda}\)</kurt>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The Wald distribution is named for Abraham Wald.</history>
</distribution>

<distribution id="Weibull">
	<name>Weibull distribution</name>
	<type>continuous</type>
	<model>The Weibull distribution is used to model the failure times.</model>
	<parameter>\(k \in (0, \infty)\), the shape parameter</parameter>
	<parameter>\(\lambda \in (0, \infty)\), the scale parameter</parameter>
	<pdf>\(f(x) = \frac{k}{\lambda} \left(\frac{x}{\lambda}\right)^{k-1} \exp\left(-\left(\frac{x}{\lambda}\right)^k\right), \; x \in (0, \infty)\)</pdf>
	<mode>\(\lambda \left(\frac{k-1}{k}\right)^{1/k}, \; k \in (1, \infty)\)</mode>
	<cdf>\(F(x) = 1 - \exp\left(-\left(\frac{x}{\lambda}\right)^k\right), \; x \in (0, \infty)\)</cdf>
	<qf>\(Q(p) = \lambda \left(- \ln(1 - p)\right)^{1/k}, \; p \in (0, 1)\)</qf>
	<mgf>\(M(t) = \sum_{n=0}^\infty \frac{t^n \lambda^n}{n!} \Gamma\left(1 + \frac{n}{k}\right), \; t \in (-\infty, \infty, \; k \in (1, \infty)\) where \(\Gamma\) is the gamma function</mgf>
	<cf>\(\varphi(t) = \sum_{n=0}^\infty \frac{(i t)^n \lambda^n}{n!} \Gamma\left(1 + \frac{n}{k}\right), \; t \in (-\infty, \infty)\) where \(\Gamma\) is the gamma function.</cf>
	<mean>\(\lambda \Gamma\left(1 + \frac{1}{k}\right)\) where \(\Gamma\) is the gamma function</mean>
	<variance>\(\lambda^2 \left[\Gamma\left(1 + \frac{2}{k}\right) - \Gamma^2\left(1 + \frac{1}{k}\right) \right]\) where \(\Gamma\) is the gamma function</variance>
	<skew>\(\frac{\Gamma(1 + 3/k) -3 \Gamma(1 + 1/k) \Gamma(1 + 2/k) + 2 \Gamma^3(1 + 1/k)}{[\Gamma(1 + 3/k) - \Gamma^2(1 + 1/k)]^{3/2}}\)</skew>
	<kurt>\(\frac{-6 \Gamma^4(1 + 1/k) + 12 \Gamma^2(1 + 1/k) \Gamma(1 + 2/k) -3 \Gamma^2(1 + 2/k) - 4 \Gamma(1 + 1/k)\Gamma(1 + 3/k) + \Gamma(1 + 4/k)}{[\Gamma(1 + 2/k) - \Gamma^2(1 + 1/k)]^2}\)</kurt>
	<median>\(\lambda [\ln(2)]^{1/k}\)</median>
	<q1>\(\lambda [\ln(4) - \ln(3)]^{1/k}\)</q1>
	<q3>\(\lambda [\ln(4)]^{1/k}\)</q3>
	<family>exponential </family>
	<family>scale</family>
	<history>The Weibull distribution is named for Waloddi Weibull who published a paper on the distribution in 1951. The distribution was used earlier by Maurice Frechet. The term <q>Weibull distribution</q> was first used in 1955 in a paper by Julius Lieblein.</history>
</distribution>

<distribution id="zeta">
	<name>zeta distribution</name>
	<name>Zipf distribution</name>
	<type>discrete</type>
	<model>The zeta distribution models ranks and sizes of certain randomly chosen items.</model>
	<parameter>\(s \in [1, \infty)\)</parameter>
	<support>\(\{1, 2, \ldots\}\)</support>
	<pdf>\(f(x) = \frac{x^{-s}}{\zeta(s)}, \; x \in \{1, 2, \ldots\}\) where \(\zeta\) is the zeta function</pdf>
	<mode>\(1\)</mode>
	<cdf>\(F(x) = \sum_{n=1}^x f(n), \; x \in \{1, 2, \ldots\}\) where \(f\) is the probability density function</cdf>
	<qf>\(Q(p) = F^{-1}(p), \; p \in [0, 1)\) where \(F\) is the distribution function</qf>
	<mean>\(\frac{\zeta(s - 1)}{\zeta(s)}, \; s \in (2, \infty)\)</mean>
	<variance>\(\frac{\zeta(s - 2)}{\zeta(s)} - \left[\frac{\zeta(s - 1)}{\zeta(s)}\right]^2\)</variance>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the quantile function</q3>
	<history>The Zipf distribution is named for the American linguist George Kingsley Zipf, who studied the distribution in the context of the frequency of words.</history>
</distribution>

<distribution id="location-scale">
	<name>location-scale distribution</name>
	<type>continuous</type>
	<model>Location scale distributions correspond to linear transformations (with positive slope) of a basic random variable, and often correspond to a change of units in a physical problem.</model>
	<parameter>the standard distribution, a continuous distribution with support on an interval \(S_0\)</parameter>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(\sigma \in (0, \infty)\), the scale parameter</parameter>
	<support>\(S = \{\mu + \sigma x: x \in S_0\}\)</support>
	<pdf>\(f(x) = \frac{1}{\sigma} f_0\left(\frac{x - \mu}{\sigma}\right), \; x \in S\) where \(f_0\) is the probability density function of the standard distribution</pdf>
	<mode>\(\mu + \sigma x_0\) where \(x_0\) is a mode of the standard distribution</mode>
	<cdf>\(F(x) = F_0\left(\frac{x - \mu}{\sigma}\right), \; x \in S\) where \(F_0\) is the distribution function of the standard distribution</cdf>
	<qf>\(Q(p) = \mu + \sigma Q_0(p), \; p \in (0, 1)\) where \(Q_0\) is the quantile function of the standard distribution</qf>
	<mgf>\(M(t) = e^{\mu t} M_0(\sigma t)\) where \(M_0\) is the moment generating function of the standard distribution</mgf>
	<cf>\(\varphi(t) = e^{i \mu t} \varphi_0(\sigma t)\) where \(\phi\) is the characteristic function of the standard distribution</cf>
	<moments type="raw">\(m(n) = \sum_{i=0}^n {n \choose i} \sigma^i \mu^{n-i} m_0(i), \; n \in \{1, 2, \ldots\}\) where \(m_0(i)\) is the \(i\)th raw moment of the standard distribution</moments>
	<mean>\(\mu + \sigma \mu_0\) where \(\mu_0\) is the mean of the standard distribution</mean>
	<variance>\(\sigma^2 \sigma_0^2\) where \(\sigma_0^2\) is the variance of the standard distribution</variance>
	<skew>\(\gamma_{0,1}\) where \(\gamma_{0,1}\) is the skewness of the standard distribution</skew>
	<kurt>\(\gamma_{0,2}\) where \(\gamma_{0,2}\) is the kurtosis of the standard distribution</kurt>
	<entropy>\(\ln(\sigma) + I_0\) where \(I_0\) is the entropy of the standard distribution</entropy>
	<median>\(\mu + \sigma q_{0,2}\) where \(q_{0,2}\) is the median of the standard distribution</median>
	<q1>\(\mu + \sigma q_{0,1}\) where \(q_{0,1}\) is the first quartile of the standard distribution</q1>
	<q3>\(\mu + \sigma q_{0,3}\) where \(q_{0,3}\) is the third quartile of the standard distribution</q3>
</distribution>

<distribution id="folded-normal">
	<name>folded normal distribution</name>
	<type>continuous</type>
	<model>The folded normal distribution governs \(|X|\) when \(X\) has a normal distribution</model>
	<parameter>\(\mu \in (-\infty, \infty)\), the location parameter</parameter>
	<parameter>\(\sigma \in (0, \infty\), the scale parameter</parameter>
	<support>\([0, \infty)\)</support>
	<pdf>\(f(x) = \frac{1}{\sigma \sqrt{2 \pi}} \left[ \exp\left(-\frac{(x + \mu)^2}{2 \sigma^2}\right) + \exp \left(-\frac{(x - \mu)^2}{2 \sigma^2}\right) \right], \quad x \in (0, \infty)\) </pdf>
	<mode>0</mode>
	<cdf>\(F(x) = \frac{1}{2} \left[ \erf\left(\frac{x + \mu}{\sqrt{2} \sigma} \right) + \erf\left(\frac{x - \mu}{\sqrt{2}\sigma}\right)\right], \quad x \in [0, \infty)\) where \(\erf\) is the error function</cdf>
	<qf>\(F^{-1}(p), p \in (0, 1)\) where \(F\) is the distribution funciton</qf>
	<mean>\(\sigma \sqrt{\frac{2}{\pi}} \exp\left(-\frac{\mu^2}{2 \sigma^2} \right) + \mu\left[1 - 2 \Phi\left(-\frac{\mu}{\sigma}\right) \right]\) where \(\Phi\) is the standard normal distribution function</mean>
	<variance>\(\mu^2 + \sigma^2 - \left\{\sigma \sqrt{\frac{2}{\pi}} \exp\left(-\frac{\mu^2}{2 \sigma^2} \right) + \mu \left[1 - 2 \Phi(-\frac{\mu}{\sigma}\right]\right\}^2\) where \(\Phi\) is the standard normal distribution function</variance>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the qunatile function</q3>
</distribution>

<distribution id="half-normal">
	<name>half normal distributon</name>
	<type>continuous</type>
	<model>The half normal distribution governs \(|X|\) when \(X\) has a normal disstribution with mean 0.</model>
	<parameter>\(\sigma \in (0, \infty\), the scale parameter</parameter>
	<support>\([0, \infty)\)</support>
	<pdf>\(f(x) = \sqrt{\frac{2}{\sigma \pi}} \exp\left(-\frac{x^2}{2 \sigma^2}\right), \quad x \in [0, \infty)\)</pdf>
	<mode>0</mode>
	<cdf>\(F(x) = \erf \left(\frac{y}{\sqrt{2} \sigma} \right), \quad x \in [0, \infty)\), where \(\erf\) is the error function</cdf>
	<qf>\(Q(p) = F^{-1}(p)\) where \(F\) is the distribution function</qf>
	<mean>\(\sigma \sqrt{\frac{2}{\pi}}\)</mean>
	<variance>\(\sigma^2 \left(1 - \frac{2}{\pi}\right)\)</variance>
	<entropy>\(\frac{1}{2} \log\left(\frac{\pi \sigma^2}{2}\right) + \frac{1}{2}\)</entropy>
	<moments type="raw">\(\mu(n) = \frac{\pi^{(n-1)/2}}{\sigma^n} \Gamma\left(\frac{1}{2}(n + 1) \right)\) where \(\Gamma\) is the gamma function</moments >
	<skew>\(\frac{\sqrt{2}(4 - \pi)}{(\pi - 2)^{3/2}}\)</skew>
	<kurt>\(\frac{8(\pi - 3)}{(\pi - 2)^2}\)</kurt>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4}\) where \(Q\) is the qunatile function</q3>
</distribution>

<distribution id="birthday">
	<name>birthday distribtuion</name>
	<name>occupancy distribution</name>
	<type>discrete</type>
	<model>This distribution models the number of empty cells when \(n\) balls are distributed at random into \(m\) cells</model>
	<parameter>\(m \in \{1, 2, \ldots\}\), the number of cells</parameter>
	<parameter>\(n \in \{1, 2, \ldots\}\), the number of balls</parameter>
	<support>\(\{\max\{m-n, 0\}, \ldots, m - 1\}\)</support>
	<pdf>\(f(x) = \binom{m}{x} \sum_{j=0}^{m-x} (-1)^j \binom{m - x}{j} \left(1 - \frac{x + j}{m}\right)^n, \quad x \in \{\max\{m-n,0\}, \ldots, m-1\}\)</pdf>
	<cdf>\(F(x) = \sum_{j = 0}^x f(j), \quad x \in \{0, 1, \ldots, n\}\) where \(f\) is the probability density function </cdf>
	<moments type="factorial">\(\mu_{(k)} = \frac{m!}{(m - k)!} \left(\frac{m - k}{m} \right)^n, \quad k \in \{1, 2, \ldots\}\)</moments>
	<gf type="probability">\(G(t) = \sum_{k=0}^m \binom{m}{k} \left(\frac{m - k}{m}\right)^n (t - 1)^k, \quad t \in \R\)</gf>
	<mean>\(m \left(1 - \frac{1}{m}\right)^n\)</mean>
	<variance>\(m (m - 1) \left(1 - \frac{2}{m}\right)^n + m \left(1 - \frac{1}{m}\right)^n - m^2 \left(1 - \frac{1}{m}\right)^{2n}\)</variance>
	<skew>\(\frac{\mu_3 - 3 \mu_1 \mu_2 + 2 \mu_1^2}{\sigma^3}\) where \(\mu_i\) is the \(i\)th raw moment and \(\sigma\) is the standard deviation</skew>
	<kurt type="excess">\(\frac{\mu_4 - 4 \mu_1 \mu_3 + 6 \mu_1^2 -3 \mu_1^4}{\sigma^4} - 3\) where \(\mu_i\) is the \(i\)th raw moment and \(\sigma\) is the standard deviation</kurt>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the qunatile function</q3>
	<entropy>\(H = -\sum_{x=0}^n \log[f(x)] f(x)\) where \(f\) is the probability density function</entropy>
</distribution>

<distribution id="matching">
	<name>matching distribtuion</name>
	<type>discrete</type>
	<model>The matching distribution governs the number of matches in a random permutation of \(\{1, 2, \ldots, n\}\)</model>
	<parameter>\(n \in \{2, 3, \ldots\}\), the number of objects permuted</parameter>
	<support>\(\{0, 1, \ldots, n\}\)</support>
	<pdf>\(f(x) = \frac{1}{x!} \sum_{j=0}^{n - x} \frac{(-1)^j}{j!}, \; x \in \{0, 1, \ldots, n\}\)</pdf>
	<mode>\(0\) if \(n\) is even; \(1\) if \(n\) is odd</mode>
	<cdf>\(F(x) = \sum_{j = 0}^x f(j), \; x \in \{0, 1, \ldots, n\}\) where \(f\) is the probability density function </cdf>
	<moments type="factorial">\(\mu_{(k)} = 1, \; k \in \{1, 2, \ldots, n\}; \quad \mu_{(k)} = 0, \; k \in \{n + 1, n + 2, \ldots\}\)</moments>
	<gf type="factorial-moment">\(G(t) = \sum_{k=1}^n \frac{(t-1)^k}{k!}, \; t \in \R\)</gf>
	<mean>\(1\)</mean>
	<variance>\(1\)</variance>
	<skew>\(\frac{\mu_3 - 3 \mu_1 \mu_2 + 2 \mu_1^2}{\sigma^3}\) where \(\mu_i\) is the \(i\)th raw moment and \(\sigma\) is the standard deviation</skew>
	<kurt type="excess">\(\frac{\mu_4 - 4 \mu_1 \mu_3 + 6 \mu_1^2 -3 \mu_1^4}{\sigma^4} - 3\) where \(\mu_i\) is the \(i\)th raw moment and \(\sigma\) is the standard deviation</kurt>
	<qf>\(Q(p) = F^{-1}(p), \quad p \in (0, 1)\) where \(F\) is the distribution function</qf>
	<median>\(Q(\frac{1}{2})\) where \(Q\) is the quantile function</median>
	<q1>\(Q(\frac{1}{4})\) where \(Q\) is the quantile function</q1>
	<q3>\(Q(\frac{3}{4})\) where \(Q\) is the qunatile function</q3>
	<entropy>\(H = -\sum_{x=0}^n \log[f(x)] f(x)\) where \(f\) is the probability density function</entropy>
	<history>The matching problem was first formulated by Pierre-Redmond Montmort.</history>
</distribution>

<distribution id="coupon">
	<name>coupon-collector distribution</name>
	<type>discrete</type>
	<model>This distribution models the number number of samples needed to obtain \(k\) distinct values when sampling at random, with replacement from a population of \(m\) objects</model>
	<parameter>\(m \in \{1, 2, \ldots\}\), the population size</parameter>
	<parameter>\(k \in \{1, 2, \ldots\}\), the number of distinct values to be obtained</parameter>
	<support>\(\{k, k + 1, \ldots\}\)</support>
	<pdf>\(f(x) = \binom{m - 1}{k - 1} \sum_{j=0}^{k-1} \binom{k-1}{j} \left(\frac{k - j - 1}{m}\right)^{x-1}, \quad x \in \{k, k + 1, \ldots\}\)</pdf>
	<cdf>\(F(x) = \sum_{j = 0}^x f(j), \quad x \in \{k, k + 1, \ldots\}\) where \(f\) is the probability density function </cdf>
	<gf type="probability">\(G(t) = \prod_{i=1}^k \frac{m - (i - 1)}{m - (i - 1)t}, \quad |t| \lt \frac{m}{k - 1} \)</gf>
	<mean>\(\sum_{i=1}^k \frac{m}{m - i + 1}\)</mean>
	<variance>\(\sum_{i=1}^k \frac{(i-1)m}{(m - i + 1)^2}\)</variance>
</distribution>

<distribution id="finite-order">
	<name>finite order statistic distribution</name>
	<type>discrete</type>
	<model>This distribution models an order statistic when a sample is chosen at random, without replacement, from a finite, ordered population</model>
	<parameter>\(m \in \{1, 2, \ldots\}\), the population size</parameter>
	<parameter>\(n \in \{1, 2, \ldots, m\}\), the sample size</parameter>
	<parameter>\(k \in \{1, 2, \ldots, n\}\), the the order</parameter>
	<support>\(\{k, k + 1, \ldots, m - n + 1\}\)</support>
	<pdf>\(f(x) = \frac{\binom{x-1}{k-1} \binom{m-x}{n-k}}{\binom{m}{n}}, \quad x \in \{k, k + 1, \quad m - n + 1\}\)</pdf>
	<mean>\(k \frac{m+1}{n+1}\)</mean>
	<median></median>
	<variance>\(k(n - k + 1) \frac{(m + 1)(m - n)}{(m + 1)^2 (n + 2)}\)</variance>
</distribution>
</distributions>

<relations>
<relation id="Bernoulli/binomial">
	<from>Bernoulli distribution</from>
	<to>binomial distribution</to>
	<statement>If \((X_1, X_2, \ldots, X_n)\) is a sequence of independent Bernoulli variables, each with parameter \(p \in [0, 1]\) then \(Y = \sum_{i = 1}^n X_i\) has the binomial distribution with parameters \(n\) and \(p\).</statement>
	<type>convolution</type>
</relation>

<relation id="Bernoulli/geometric">
	<from>Bernoulli distribution</from>
	<to>geometric distribution</to>
	<statement>If \((X_1, X_2, \ldots)\) is a sequence of independent Bernoulli variables, each with parameter \(p \in (0, 1)\), then \(Y = \min\{n \in \{1, 2, \ldots\}: X_n = 1\}\) has the geometric distribution with parameter \(p\).</statement>
	<type>transformation</type>
</relation>

<relation id="Bernoulli/negative-binomial"> 
	<from>Bernoulli distribution</from>
	<to>negative binomial distribution</to>
	<statement>If \((X_1, X_2, \ldots)\) is a sequence of independent Bernoulli variables, each with parameter \(p \in (0, 1)\), then for \(ki \in \{1, 2, \ldots\}\), \(Y = \min\{n \in \{1, 2, \ldots\}: \sum_{i=1}^n X_i = k\}\) has the negative binomial distribution with parmeters \(k\) and \(p\).</statement>
	<type>transformation</type>
</relation>

<relation id="Bernoulli/Rademacher">
	<from>Bernoulli distribution</from>
	<to>Rademacher distribution</to>
	<statement>If \(X\) has the Bernoulli distribution with parameter \(\frac{1}{2}\) then \(2 X - 1\) has the Rademacher distribution.</statement>
	<type>linear transformation</type>
</relation>

<relation id="beta/arcsine">
	<from>beta distribution</from>
	<to>arcsine distribution</to>
	<statement>The beta distribution with parameters \(\alpha = \frac{1}{2}\) and \(\beta = \frac{1}{2}\) is the arcsine distribution.</statement>
	<type>special case</type>
</relation>

<relation id="beta/standard-uniform">
	<from>beta distribution</from>
	<to>standard uniform distribution</to>
	<statement>The beta distribution with parameters \(\alpha = 1\) and \(\beta = 1\) is the standard uniform distribution.</statement>
	<type>special case</type>
</relation>

<relation id="beta/inverse-beta">
	<from>beta distribution</from>
	<to>inverse beta distribution</to>
	<statement>If \(X\) has the beta distribution with parameters \(\alpha \in (0, \infty)\) and \(\beta \in (0, \infty)\), then \(Y = \frac{X}{1 - X}\) has the inverse beta distribution with parameters \(\alpha\) and \(\beta\).</statement>
	<type>transformation</type>
</relation>

<relation id="beta/semicirce">
	<from>beta distribution</from>
	<to>semicircle distribution</to>
	<statement>If \(X\) has the beta distribution with parameters \(\alpha = \frac{3}{2}\) and \(\beta = \frac{3}{2}\), and \(r \in (0, \infty)\), then \(Y = r (2 X - 1)\) has the semicircle distribution with parameter \(r\).</statement>
	<type>transformation</type>
</relation>

<relation id="beta/beta">
	<from>beta distribution</from>
	<to>beta distribution</to>
	<statement>If \(X\) has the beta distribution with parameters \(\alpha \in (0, \infty)\) and \(\beta \in (0, \infty)\) then \(Y = 1 - X\) has the beta distribution with parameters \(\beta\) and \(\alpha\).</statement>
	<type>transformation</type>
</relation>

<relation id="r"> %beta to beta
	<from>beta distribution</from>
	<to>beta distribution</to>
	<statement>If \(X\) has the beta distribution with parameters \(\alpha \in (0, \infty)\) and \(\beta = 1\), and \(r \in (0, \infty)\), then \(Y = X^r\) has the beta distribution with parameters \(\frac{\alpha}{r}\) and \(1\).</statement>
	<type>transformation</type>
</relation>

<relation id="beta/Pareto">
	<from>beta distribution</from>
	<to>Pareto distribution</to>
	<statement>If \(X\) has the beta distribution with left parameter \(\alpha \in (0, \infty)\) and right parameter \(1\), then \(Y = \frac{1}{X}\) has the Pareto distribution with shape parameter \(\alpha\).</statement>
	<type>transformation</type>
</relation>

<relation id="beta/binomial/beta-binomial">
	<from>beta distribution</from>
	<from>binomial distribution</from>
	<to>beta-binomial distribution</to>
	<statement>If \(P\) has the beta distribution with parameters \(\alpha \in (0, \infty)\) and \(\beta \in (0, \infty)\) and if the conditional distribution of \(X\) given \(P = p\) has the binomial distribution with parameters \(n \in \{1, 2, \ldots\}\) and \(p\), then \(X\) has the beta-binomial distribution with parameters \(n\), \(\alpha\), and \(\beta\).</statement>
	<type>Conditioning</type>
</relation>

<relation id="binomial/standard-normal"> 
	<from>binomial distribution</from>
	<to>standard normal distribution</to>
	<statement>If \(X_n\) has the binomial distribution with parameters \(n \in \{1, 2, \ldots\}\) and fixed \(p \in (0, 1)\) then then the distribution of \(Z_n = \frac{X_n - n p}{\sqrt{n p (1 - p)}}\) converges to the standard normal distribution as \(n \to \infty\).</statement>
	<type>central limit theorem</type>
	<cite>Dinov Christou Sanchez 2008</cite>
</relation>

<relation id="binomial/Bernoulli">
	<from>binomial distribution</from>
	<to>Bernoulli distribution</to>
	<statement>The binomial distribution with parameters \(n = 1\) and \(p \in [0, 1]\) is the Bernoulli distribution with parameter \(p\).</statement>
	<type>special case</type>
</relation>

<relation id="binomial/binomial">
	<from>binomial distribution</from>
	<to>binomial distribution</to>
	<statement>If \(X\) has the binomial distribution with parameters \(n \in \{1, 2, \ldots\}\) and \(p \in [0, 1]\); \(Y\) has the binomial distribution with parameters \(m \in \{1, 2, \ldots\}\) and \(p\); and \(X\) and \(Y\) are independent, then \(X + Y\) has the binomial distribution with parameters \(m + n\) and \(p\).</statement>
	<type>convolution</type>
</relation>

<relation id="binomial/hypergeometric">
	<from>binomial distribution</from>
	<to>hypergeometric distribution</to>
	<statement>Suppose that \(\boldsymbol{X} = (X_1, X_2, \ldots)\) is a Bernoulli trials sequence with parameter \(p \in (0, 1)\). For \(n \in \{1, 2, \ldots\}\) let \(Y_n = \sum_{i=1}^n X_i\), so that \(Y_n\) has the binomial distribution with parameters \(n\) and \(p\). If \(m \lt n\) then the distribution of \(Y_m\) given \(Y_n = k\) is hypergeoemtric with parameters \(m\), \(n\), and \(k\).</statement>
	<type>Conditional distribution</type>
</relation>

<relation id="binomial/Poisson">
	<from>binomial distribution</from>
	<to>Poisson distribution</to>
	<statement>The binomial distribution with parameters \(n \in \{1, 2, \ldots\}\) and \(p \in (0, 1)\) converges to the Poisson distribution with parameter \(\lambda \in (0, \infty)\) if \(n \to \infty\), \(p \to 0\), with \(n p \to \lambda\).</statement>
	<type>parameter limit</type>
</relation>

<relation id="binomial/negative-binomial">
	<from>binomial distribution</from>
	<to>negative binomial distribution</to>
	<statement>For \(n \in \{1, 2, \ldots\}\), let \(Y_n\) denote the number of successes in the first \(n\) of a sequence of Bernoulli trials, so that \(Y_n\) has the binomial distribution with trial parameter \(n\) and sucess parameter \(p\). Then for \(k \in \{1, 2, \ldots\}\), \(Z_k = \min\{n: Y_n \geq k\} - k\) has the negative binomial distribution with stopping parameter \(k\) and success parameter \(p\).</statement>
	<type>inverse stochastic process</type>
</relation>

<relation id="Cauchy/Cauchy.1">
	<from>Cauchy Distribution</from>
	<to>Cauchy Distribution</to>
	<statement>If \(X\) has the Cauchy distribution with location parameter \(\alpha_1 \in (-\infty, \infty)\) and location parameter \(\beta_1 \in (0, \infty)\), \(Y\) has the Cauchy distribution with location parameter \(\alpha_2 \in (-\infty, \infty)\) and scale parameter \(\beta_2 \in (0, \infty)\), and \(X\) and \(Y\) are independent, then \(X + Y\) has the Cauchy distribution with location parameter \(\alpha_1 + \alpha_2\) and scale parameter \(\beta_1 + \beta_2\).</statement>
	<type>convolution</type>
</relation>

<relation id="Cauchy/Cauchy.2">
	<from>Cauchy distribution </from>
	<to>Cauchy distribution</to>
	<statement>If \(X\) has Cauchy distribution with location parameter \(\alpha \in (-\infty, \infty)\) and scale parameter \(\beta \in (0, \infty)\), \(a \in (-\infty, \infty)\) and \(b \in (0, \infty)\), then \(a + b X\) has the Cauchy distribution with location parameter \(a + b \alpha\) and location parameter \(\beta b\).</statement>
	<type>location-scale transformation</type>
</relation>

<relation id="chi-square/chi-square">
	<from>chi-square distribution</from>
	<to>chi-square distribution</to>
	<statement>If \(X\) has the chi-square distribution with \(m \in (0, \infty)\) degrees of freedom; \(Y\) has the chi-square distribution with \(n \in (0, \infty)\) degrees of freedom; and \(X\) and \(Y\) are independent, then \(X + Y\) has the chi-square distribution with \(m + n\) degrees of freedom.</statement>
	<type>convolution</type>
</relation>

<relation id="chi-square/gamma">
	<from>chi-square distribution</from>
	<to>gamma distribution</to>
	<statement>If \(X\) has a chi-square distribution with \(\nu \in \{1, 2, \ldots\}\) degrees of freedom, and \(c \in (0, \infty)\) , then \(Y = c X\) has the gamma distribution with shape parameter \(k = \frac{\nu}{2}\) and scale parameter \(\theta = 2 c\).</statement>
	<type>scale transformation</type>
</relation>

<relation id="chi-square/standard-normal">
	<from>chi-square distribution</from>
	<to>standard normal distribution</to>
	<statement>If \(X_n\) has the chi-square distribution with \(n \in \{1, 2, \ldots\}\) degrees of freedom, then the distribution of \(Z = \frac{X_n - n}{\sqrt{2 n}}\) converges to the standard normal distribution as \(n \to \infty\).</statement>
	<type>central limit theorem</type>
	<cite>Dinov Christou Sanchez 2008</cite>
</relation>

<relation id="chi-square/F">
	<from>chi-square distribution</from>
	<to>F-distribution</to>
	<statement>If \(U\) has the chi-square distribution with \(m \in \{1, 2, \ldots\}\) degrees of freedom; \(V\) has the chi-square distribution with \(n \in \{1, 2, \ldots\}\) degrees of freedom; and \(U\) and \(V\) are independent, then \(X = \frac{U/m}{V/n}\) hs the \(F\)-distribution with \(m\) degrees of freedom in the numerator and \(n\) degrees of freedom in the denominator</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="chi-square-noncentral/chi-squre"> 
	<from>non-central chi-square distribution</from>
	<to>chi-square distribution</to>
	<statement>If \(X\) has the non-central chi-square distribution with \(\nu \in \{1, 2, \ldots\}\) degrees of freedom and non-centrality parameter \(\lambda = 0\), then \(X\) has a chi-square distribution with \(\nu\) degrees of freedom.</statement>
	<type>special case</type>
</relation>

<relation id="chi-square/chi">
	<from>chi-square distribution</from>
	<to>chi distribution</to>
	<statement>If \(X\) has the chi-square distribution with \(n \in \{1, 2, \ldots\}\) degrees of freedom, then \(\sqrt{X}\) has the chi distribution with \(n\) degrees of freedom.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="chi-square/standard-normal/student"> 
	<from>chi-square distribution</from>
	<from>standard normal distribution</from>
	<to>Student's t-distribution</to>
	<statement>If \(Z\) has the standard normal distribution, \(V\) has the chi-square distribution with \(n \in (0, \infty)\) degrees of freedom, and \(Z\) and \(V\) are independent, then \(T = \frac{Z}{\sqrt{V / n}}\) has the Student's's \(t\)-distribution with \(n\) degrees of freedom.</statement>
	<type>transformation</type>
</relation>

<relation id="chi-square/Poisson/Rice">
	<from>chi-square distribution</from>
	<from>Poisson distribution</from>
	<to>Rice distribution</to>
	<statement>If \(X\) has the Poisson distribution with parameter \(\frac{\nu^2}{2 \sigma^2}\) where \(\nu \in (0, \infty)\) and \(\sigma \in (0, \infty)\), and the conditional distribution of \(Y\) given \(X = x \in \{0, 1, 2, \ldots\}\) is chi-square with \(2 x + 2\) degrees of freedom, then \(\sigma \sqrt{X}\) has the Rice distribution with distance parameter \(\nu\) and scale parameter \(\sigma\).</statement>
	<type>mixture and transformation</type>
</relation>

<relation id="continuous-uniform/continuous-uniform"> 
	<from>continuous uniform distribution</from>
	<to>continuous uniform distribution</to>
	<statement>If \(X\) is uniformly distributed on the interval \([a, b]\) and \(c, d \in (-\infty, \infty)\) with \(c \ne 0\), then \(Y = cX + d\) is uniformly distributed on \([ca + d, cb + d]\) if \(c \gt 0\) or on \([cb + d, ca + d]\) if \(c \lt 0\)</statement>
	<type>linear transformation</type>
</relation>

<relation id="continuous-uniform/standard-uniform">
	<from>continuous uniform distribution</from>
	<to>standard uniform distribution</to>
	<statement>The continuous uniform distribution on \([0, 1]\) is the standard uniform distribution</statement>
	<type>special case</type>
</relation>

<relation id="continuous-uniform/triangular">
	<from>continuous uniform distribution</from>
	<to>triangular distribution</to>
	<statement>If \(X\) and \(Y\) are independent and each is uniformly distributed on the interval \([a, b]\), then \(X + Y\) has the triangular distribution with parameters \(a\), \(b\), and \(c = \frac{a+b}{2}\).</statement>
	<type>convolution</type>
</relation>

<relation id="continuous-uniform/exponential">
	<from>standard uniform distribtion</from>
	<to>exponential distribution</to>
	<statement>If \(X\) has the standard uniform distribution and \(\beta \in (0, \infty)\), then \(-\beta \ln(1 - X)\) has the exponential distribution with scale parameter \(\beta\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="continuous-uniform/Pareto">
	<from>standard uniform distribution</from>
	<to>Pareto distribution</to>
	<statement>If \(X\) has the standard uniform distribution, \(\mu \in (-\infty, \infty)\), and \(\beta \in (0, \infty)\) then \(\frac{\mu}{(1 - X)^{1/\beta}}\) has the Pareto distribution with location parameter \(\mu\) and shape parameter \(\beta\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/beta"> 
	<from>standard uniform distribution</from>
	<to>beta distribution</to>
	<statement>If \(X\) has the standard uniform distribution and \(\alpha \in (0, \infty)\) then \(X^{1/\alpha}\) has the beta distribution with left parameter \(\alpha\) and right parameter 1.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/standard-Cauchy">
	<from>standard uniform distribution</from>
	<to>standard Cauchy distribution</to>
	<statement>If \(X\) has the standard uniform distribution then \(\tan[\pi(X - \frac{1}{2})]\) has the standard Cauchy distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/arcsine">
	<from>standard uniform distribution</from>
	<to>arcsine distribution</to>
	<statement>If \(X\) has the standard uniform distribution then \(\sin^2(\frac{\pi}{2} X)\) has the arcsine distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/exponential-logarithmic">
	<from>standard uniform distribution</from>
	<to>exponential-logarithmic distribution</to>
	<statement>If \(X\) has the standard uniform distribution, \(b \in (0, \infty)\), and \(p \in (0, 1)\) then \(\frac{1}{b}\ln\left(\frac{1 - p}{1 - p^{1 - X}}\right)\) has the exponential-logarithmic distribution with parameters \(b\) and \(p\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/geometric">
	<from>standard uniform distribution</from>
	<to>geometric distribution</to>
	<statement>If \(X\) has the standard uniform distribution and \(p \in (0, 1)\) then \(\lceil \frac{\ln(1 - X)}{\ln(1 - p)}\rceil\) has the geometric distribution with parameter \(p\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/Gumbel">
	<from>standard uniform distribution</from>
	<to>Gumbel distribution</to>
	<statement>If \(X\) has the standard uniform distribution, \(\mu \in (-\infty, \infty)\), and \(\sigma \in (0, \infty)\) then \(\mu - \sigma \ln(-\ln(X))\) has the Gumbel distribution with location prarameter \(\mu\) and scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/hyperbolic-secant">
	<from>standard uniform distribution</from>
	<to>hyperbolic secant distrbution</to>
	<statement>If \(X\) has the standard uniform distribution then \(\frac{2}{\pi} \ln[\tan(\frac{\pi}{2} X)]\) has the hyperbolic secant distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/Laplace">
	<from>standard uniform distributon</from>
	<to>Laplace distribution</to>
	<statement>If \(X\) has the standard uniform distribution, \(\mu \in (-\infty, \infty)\), \(b \in (0, \infty)\), then \(\mu + b \ln(2 \min\{X, 1 - X\})\) has the Laplace distribution with location parameter \(\mu\) and scale parameter \(b\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/logistic"> 
	<from>standard uniform distribution</from>
	<to>logistic distribution</to>
	<statement>If \(X\) has the standard uniform distribution, \(\mu \in (-\infty, \infty)\), and \(\sigma \in (0, \infty)\), then \(\mu + \sigma \ln\left(\frac{X}{1 - X}\right)\) has the logistic distribution with location parameter \(\mu\) and scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/log-logistic">
	<from>standard uniform distribution</from>
	<to>log-logistic distribution</to>
	<statement>If \(X\) has the standard uniform distribution, \(\alpha \in (0, \infty)\), and \(\beta \in (0, \infty)\), then \(\alpha \left(\frac{X}{1 - X}\right)^{1/\beta}\) has the log-logistic distribution with scale parameter \(\alpha\) and shape parameter \(\beta\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/Rayleigh">
	<from>standard uniform distribution</from>
	<to>Rayleigh distribution</to>
	<statement>If \(X\) has the standard uniform distribution and \(\sigma \in (0, \infty)\), then \(\sigma \sqrt{-2 \ln(1 - X)}\) has the Rayleigh distribution with scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/Weibull">
	<from>standard uniform distribution</from>
	<to>Weibull distribution</to>
	<statement>If \(X\) has the standard uniform distribution, \(\sigma \in (0, \infty)\) and \(\alpha \in (0, \infty)\), then \(\sigma (-\ln(1 - X))^{1/\alpha}\) has the Weibull distribution with shape parameter \(\alpha\) and scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-uniform/Irwin-Hall">
	<from>standard uniform distribution</from>
	<to>Irwin-Hall distribution</to>
	<statement>If \((X_1, X_2, \ldots, X_n)\) is a sequence of independent random variables, each with the standard uniform distribution, then \(sum_{i=1}^n X_i\) has the Irwin-Hall distribution with parameter \(n\).</statement>
	<type>convolution</type>
</relation>

<relation id="exponential/exponential">
	<from>exponential distribution</from>
	<to>exponential distribution</to>
	<statement>If \(X\) has the exponential distribution with rate parameter \(r \in (0, \infty)\), \(Y\) has the exponential distribution with rate parameter \(s \in (0, \infty)\), and \(X\) and \(Y\) are independent, then \(\min\{X, Y\}\) has the exponential distribution with rate parameter \(r + s\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="exponential/standard-uniform">
	<from>exponential distribution</from>
	<to>standard uniform distribution</to>
	<statement>If \(X\) has the exponential distribution with parameter \(\lambda \in (0, \infty)\) then \(Y = e^{-\lambda X}\) has the standard uniform distribution.</statement>
	<type>transformation</type>
</relation>

<relation id="exponential/gamma">
	<from>exponential distribution</from>
	<to>gamma distribution</to>
	<statement>If \((X_1, X_2, \ldots, X_n)\) is a sequence of independent random variables, each with the exponential distribution with parameter \(\lambda \in (0, \infty)\) then \(Y = \sum_{i=1}^n X_i\) has the gamma distribution with shape parameter \(n\) and scale parameter \(\frac{1}{\lambda}\).</statement>
	<type>convolution</type>
</relation>

<relation id="exponential/Pareto">
	<from>exponential distribution</from>
	<to>Pareto distribution</to>
	<statement>If \(a \in (0, \infty)\) and \(X\) has the exponential distribution with parameter \(\lambda \in (0, \infty)\) then \(Y = a e^X\) has the Pareto distribution with scale parameter \(a\) and shape parameter \(\lambda\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="exponential/Weibull"> 
	<from>exponential distribution</from>
	<to>Weibull distribution</to>
	<statement>If \(X\) has the standard exponential distribution, \(k \in (0, \infty)\), and \(b \in (0, \infty)\), then \(Y = b X^{1/k}\) has the Weibull distribution with shape parameter \(k\) and scale parameter \(b\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="exponential/Gumbel">
	<from>exponential distribution</from>
	<to>Gumbel distribution</to>
	<statement>If \((X_1, X_2, \ldots)\) is a sequence of indpendent random variables, each with the standard exponential distribution, then the distribution of \(\max\{X_1, \ldots, X_n\} - \ln(n)\) converges to the standard Gumbel distribution.</statement>
	<type>limiting distribution</type>
</relation>

<relation id="exponential/Laplace">
	<from>exponential distribution</from>
	<to>Laplace distribution</to>
	<statement>If \(X\) and \(Y\) are independent random variables and each has the exponential distribution with scale parameter \(\sigma \in (0, \infty)\) then \(X - Y\) has the Laplace distribution with location parameter \(0\) and scale parameter \(\sigma\).</statement>
	<type>convolution</type>
</relation>

<relation id="exponential/Rademacher/Laplace">
	<from>exponential distribution</from>
	<from>Rademacher distribution</from>
	<to>Laplace distribution</to>
	<statement>If \(X\) has the exponential distribution with scale parameter \(\sigma \in (0, \infty)\), \(Y\) has the Rademacher distribution, and \(X\) and \(Y\) are independent, then \(X V\) has the Laplace distribution with location parameter \(0\) and scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="exponential/normal/Laplace">
	<from>epxonential distribution</from>
	<from>normal distribution</from>
	<to>Laplace distribution</to>
	<statement>If \(X\) has the standard exponential distribution, \(Z\) has the standard normal distribution, \(X\) and \(Z\) are independent, \(\mu \in (-\infty, \infty)\), and \(\sigma \in (0, \infty)\), then \(\mu + \sigma Z \sqrt{2 X}\) has the Laplace distribution with location parameter \(\mu\) and scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="F/F">
	<from>F-distribution</from>
	<to>F-distribution</to>
	<statement>If \(X\) has the F-distribution with \(m \in \{1, 2, \ldots\}\) degrees of freedom in the numerator and \(n \in \{1, 2, \ldots\}\) degrees of freedom in the denominator, then \(\frac{1}{X}\) has the F-distribution with \(n\) degrees of freedom in the numerator and \(m\) degrees of freedom in the denominator.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="F/beta"> 
	<from>F-distribution</from>
	<to>beta distribution</to>
	<statement>If \(X\) has the F-distribution with \(m \in (0, \infty)\) degrees of freedom in the numerator and \(n \in (0, \infty)\) degrees of freedom in the denominator, then \(\frac{(m/n)X}{1 + (m/n)X}\) has the beta distribution with left parameter \(\frac{m}{2}\) and right parameter \(\frac{n}{2}\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="F/chi-square">
	<from>F-distribution</from>
	<to>chi-square distribution</to>
	<statement>If \(X\) has the chi-square distribution with \(m \in \{1, 2, \ldots\}\) degrees of freedom in the numerator and \(n \in \{1, 2, \ldots\}\) degrees of freedom in the denominator, then the distribution of \(m X\) converges to the chi-square distribution with \(m\) degrees of freedom as \(n \to \infty\).</statement>
	<type>limiting distribution</type>
</relation>

<relation id="gamma/gamma.1">
	<from>gamma distribution</from>
	<to>gamma distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(\alpha \in (0, \infty)\) and scale parameter \(\lambda \in (0, \infty)\) and \(c \in (0, \infty)\), then \(Y = cX\) has the gamma distribution with shape parameter \(\alpha\) and scale parameter \(c \lambda\).</statement>
	<type>scale transformation</type>
</relation>

<relation id="gamma/gamma.2"> 
	<from>gamma distribution</from>
	<to>gamma distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(\alpha \in (0, \infty)\) and scale parameter \(\lambda \in (0, \infty)\), \(Y\) has the gamma distribution with shape parameter \(\beta \in (0, \infty)\) and scale parameter \(\lambda\), and \(X\) and \(Y\) are independent, then \(X + Y\) has the gamma distribution with shape parameter \(\alpha + \beta\) and scale parameter \(\lambda\).</statement>
	<type>convolution</type>
</relation>

<relation id="gamma/exponential"> 
	<from>gamma distribution</from>
	<to>exponential distribution</to>
	<statement>If \(X\) has the gamma distributed with parameter shape parameter \(k = 1\) and scale parameter \(\lambda \in (0, \infty)\) then and then \(X\) has the exponential distribution with scale parameter \(\lambda\) (and hence rate parameter \(1/\lambda\).</statement>
	<type>special case</type>
</relation>

<relation id="gamma/chi-square">
	<from>gamma distribution</from>
	<to>chi-square distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(k \in (0, \infty)\) and scale parameter \(\lambda \in (0, \infty)\), then \(\frac{2 X}{\lambda}\) has the chi-square distribution with \(k\) degrees of freedom.</statement>
	<type>linear transformation</type>
</relation>

<relation id="gamma/Erlang">
	<from>gamma distribution</from>
	<to>Erlang distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(k \in \{1, 2, \ldots\}\) and scale parameter \(c \in (0, \infty)\), then \(X\) has the Erlang distribution with shape parameter \(k\) and scale parameter \(c\).</statement>
	<type>special case</type>
</relation>
 
<relation id="gamma/Maxwell-Boltzmann"> 
	<from>gamma distribution</from>
	<to>Maxwell-Boltzmann distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(k = \frac{3}{2}\) and scale parameter \(\theta = 2 a^2\) where \(a \in (0, \infty)\), then \(\sqrt{X}\) has the Maxwell-Boltzmann distribution with parameter \(a\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="gamma/standard-normal">
	<from>gamma distribution</from>
	<to>standard normal distribution</to>
	<statement>If \(X_k\) has the gamma distribution with shape parameter \(k \in (0, \infty)\) and scale parameter \(b \in (0, \infty)\) then the distribution of \(\frac{X - k b}{\sqrt{k} b}\) converges to the standard normal distribution as \(k \to \infty\).</statement>
	<type>central limit theorem</type>
</relation>

<relation id="gamma/beta"> 
	<from>gamma distribution</from>
	<to>beta distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(\alpha \in (0, \infty)\) and scale parameter \(\lambda \in (0, \infty)\), \(Y\) has the gamma distribution with shape parameter \(\beta \in (0, \infty)\) and scale parameter \(\lambda\), and \(X\) and \(Y\) are independent, then \(\frac{X}{X + Y}\) has the beta distribution with left parameter \(\alpha\) and right parameter \(\beta\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="gamma/inverted-beta">
	<from>gamma distribution</from>
	<to>inverted beta distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(\alpha \in (0, \infty)\) and scale parameter \(\lambda \in (0, \infty)\), \(Y\) has the gamma distribution with shape parameter \(\beta \in (0, \infty)\) and scale parameter \(\lambda\), and \(X\) and \(Y\) are independent, then \(\frac{X}{Y}\) has the inverted beta distribution with shape parameters \(\alpha\) and \(\beta\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="gamma/Levy">
	<from>gamma distribution</from>
	<to>Levy distribution</to>
	<statement>If \(X\) has the gamma distribution with shape parameter \(\frac{1}{x}\) and scale parameter \(\sigma \in (0, \infty)\) then \(\frac{1}{X}\) has the Levy distribution with location parameter \(0\) and scale parameter \(\frac{2}{\sigma}\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="geometric/geometric">
	<from>geometric distribution</from>
	<to>geometric distribution</to>
	<statement>If \(X\) has the geometric distributin on \(\{0, 1, \ldots\}\) then \(X + 1\) has the geometric distribution on \(\{1, 2 \ldots\}\).</statement>
	<type>linear transformation</type>
</relation>

<relation id="geometric/discrete-uniform">
	<from>geometric distribution</from>
	<to>discrete uniform distribution</to>
	<statement>If \(X\) has the geometric distribution on \(\{1, 2, \ldots\}\) with parameter \(p \in (0, 1)\) and \(n \in \{1, 2, \ldots\}\), then the conditional distribution of \(X\) given \(X \in \{1, 2, \ldots, n\}\) converges to the uniform distribution on \(\{1, 2, \ldots, n\}\) as \(p \to 0\).</statement>
	<type>limiting conditional distribution</type>
</relation>

<relation id="geometric/exponential">
	<from>geometric distribution</from>
	<to>exponential distribution</to>
	<statement>If \(X_n\) has the geometric distribution on \(\{1, 2, \ldots\}\) with parmeter \(p_n \in (0, 1)\) for each \(n \in \{1, 2, \ldots\}\) and \(n p_n \to r \in (0, \infty)\) as \(n \to \infty\), then the distribution of \(\frac{X_n}{n}\) converges to the exponential distribution with rate parameter \(r\).</statement>
	<type>limiting distribution</type>
</relation>

<relation id="Gumbel/Gumbel">
	<from>Gumbel distribution</from>
	<to>Gumbel distribution</to>
	<statement>If \(X\) has the Gumbel distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\sigma \in (0, \infty)\), and \(a \in (-\infty, \infty)\), \(b \in (0, \infty)\), then \(a + b X\) has the Gumbel distribution with location parameter \(a + b \mu\) and scale parameter \(b \sigma\).</statement>
	<type>location-scale transformation</type>
</relation>

<relation id="Gumbel/standard-uniform">
	<from>Gumbel distribution</from>
	<to>standard uniform distribution</to>
	<statement>If \(X\) has the Gumbel distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\sigma \in (0, \infty)\) then \(\exp\left[-\exp\left(\frac{X - \mu}{\sigma}\right)\right]\) has the standard uniform distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="hypergeometric/hypergeometric">
	<from>hypergeometric distribution</from>
	<to>hypergeometric distribution</to>
	<statement>If \(X\) has the hypergeometric distribution with population size \(m \in \{1, 2, \ldots\}\), sample size \(n \in \{1, 2, \ldots, m\}\) and type parameter \(r \in \{1, 2, \ldots, m\}\) then \(n - X\) has the hypergeometric distribution with population size \(m\), sample size \(n\), and type parameter \(m - r\).</statement>
	<type>linear transformation</type>
</relation>

<relation id="hypergeometric/binomial">
	<from>hypergeometric distribution</from>
	<to>binomial distribution</to>
	<statement>Let \(n \in \{1, 2, \ldots\}\) and \(r_m \in \{1, 2, \ldots, m\}\) for each \(m \in \{1, 2, \ldots\}\) with \(\frac{r_m}{m} \to p \in (0, 1)\) as \(m \to \infty\). The hypergeometric distribution with population size \(m\), sample size \(n\), and type parameter \(r_m\) converges to the binomial distribution with trial parameter \(n\) and success parameter \(p\) as \(m \to \infty\).</statement>
	<type>limiting distribution</type>
</relation>

<relation id="hypergeometric/Bernoulli">
	<from>hypergeometric distribution</from>
	<to>Bernoulli distribution</to>
	<statement>If \(X\) has the hypergeometric distribution with population size \(m \in \{1, 2, \ldots\}\), sample size \(n = 1\), and type parameter \(r \in \{1, 2, \ldots, m\}\), then \(X\) has the Bernoulli distribution with parameter \(\frac{r}{m}\).</statement>
	<type>TBD</type>
</relation>

<relation id="hyperbolic-secant/standard-uniform">
	<from>hyperbolic secant distribution</from>
	<to>standard uniform distribution</to>
	<statement>If \(X\) has the hyperbolic secant distribution then \(\frac{2}{\pi} \arctan[\exp(\frac{\pi}{2} X)]\) has the standard uniform distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Irwin-Hall/Irwin-Hall">
	<from>Irwin-Hall distribution</from>
	<to>Irwin-Hall distribution</to>
	<statement>If \(X\) has the Irwin-Hall distribution with parameter \(m \in \{1, 2, \ldots\}\), \(Y\) has the Irwin-Hall distribution with parameter \(n \in \{1, 2, \ldots\}\), and \(X\) and \(Y\) are independent, then \(X + Y\) has the Irwin-Hall distribution with parameter \(m + n\).</statement>
	<type>convolution</type>
</relation>

<relation id="Irwin-Hall/standard-uniform">
	<from>Irwin-Hall distribution</from>
	<to>standard uniform distribution</to>
	<statement>The Irwin-Hall distribution with parameter \(1\) is the standard uniform distribution.</statement>
	<type>special case</type>
</relation>

<relation id="Irwin-Hall/triangular">
	<from>Irwin-Hall distribution</from>
	<to>triangular distribution</to>
	<statement>The Irwin-Hall distribution with parmeter \(2\) is the triangular distribution with left endpoint \(0\), right endpoint \(1\) and midpoint \(\frac{1}{2}\).</statement>
	<type>special case</type>
</relation>

<relation id="inverted-beta/inverted-beta"> 
	<from>inverted beta distribution</from>
	<to>inverted beta distribution</to>
	<statement>If \(X\) has the inverted beta distribution with shape parameters \(\alpha \in (0, \infty)\) and \(\beta \in (0, \infty)\) then \(\frac{1}{X}\) has the inverted beta distribution with shape parameters \(\beta\) and \(\alpha\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="inverted-beta/F">
	<from>inverted beta distribution</from>
	<to>F-distribution</to>
	<statement>If \(X\) has the inverted beta distribution with shape parameters \(\alpha \in (0, \infty)\) and \(\beta \in (0, \infty)\) then \(\frac{\beta}{\alpha} X\) has the F-distribution with \(2 \alpha\) degrees of freedom in the numerator and \(2 \beta\) degrees of freedom in the denominator.</statement>
	<type>linear transformation</type>
</relation>

<relation id="Laplace/exponential">
	<from>Laplace distribution</from>
	<to>exponential distribution</to>
	<statement>If \(X\) has the Laplace distribution with location parameter \(0\) and scale parameter \(\sigma \in (0, \infty)\) then \(|X|\) has the exponential distribution with scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Levy/folded-normal">
	<from>Levy distribution</from>
	<to>folded normal distribution</to>
	<statement>If \(X\) has the Levy distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\sigma \in (0, \infty)\), then \(\frac{1}{\sqrt{X - \mu}}\) has the folded normal distribution with location parameter \(0\) and scale parameter \(\frac{1}{\sigma}\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Levy/gamma"> 
	<from>Levy distribution</from>
	<to>gamma distribution</to>
	<statement>If \(X\) has the Levy distribution with location parameter \(0\) and scale parameter \(\sigma \in (0, \infty)\), then \(\frac{1}{X}\) has the gamma distribution with shape parameter \(\frac{1}{x}\) and scale parameter \(\frac{2}{\sigma}\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="logarithmic/Poisson">
	<from>logarithmic distribution</from>
	<from>Poisson distribution</from>
	<to>negative binomial distribution</to>
	<statement>If \((X_1, X_2, \ldots)\) is a sequence of independent random variables, each with the logarithmic distribution with parameter \(p \in (0, 1)\) and \(N\) has the Poisson distribution with parameter \(\lambda \in (0, \infty)\), then \(\sum_{i=1}^N X_i\) has the negative binomial distribution with parameters \(\lambda\) and \(p\).</statement>
	<type>mixture</type>
</relation>

<relation id="logistic/standard-uniform"> %logistic to standard uniform
	<from>logistic distribution</from>
	<to>standard uniform distribution</to>
	<statement>If \(X\) has the logistic distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\sigma \in (0, \infty)\) then \(\frac{1}{1 + \exp\left(\frac{X - \mu}{\sigma}\right)}\) has the standard uniform distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="logistic-skew/exponential">
	<from>skew-logistic distribution</from>
	<to>exponential distribution</to>
	<statement>If \(X\) has the skew-logistic distribution with parameter \(\alpha \in (0, \infty)\), then \(Y = \ln(1+e^{-X})\) has the exponential distribution with rate parameter \(\alpha\).</statement>
	<type>transformation</type>
</relation>

<relation id="log-normal/log-normal.1">
	<from>log-normal distribution </from>
	<to>log-normal distribution</to>
	<statement>If \(X\) has the log-normal distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\sigma \in (0, \infty)\), \(Y\) has the log-normal distribuiton with location parameter \(\nu \in (-\infty, \infty)\) and scale parameter \(\tau \in (0, \infty)\), and \(X\) and \(Y\) are independent, then \(X Y\) has the log-normal distirbution with location parameter \(\mu + \tau\) and scale parameter \(\sqrt{\sigma^2 + \tau^2}\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="log-normal/log-normal.2">
	<from>log-normal distribution</from>
	<to>log-normal distribution</to>
	<statement>If \(X\) has the log-normal distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parmaeter \(\sigma \in (0, \infty)\), and \(a \neq 0\) then \(a X\) has the log-normal distribution with location parameter \(a \mu\) and scale parameter \(|a| \sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="log-normal/log-normal.3">
	<from>log-normal distribution</from>
	<to>log-normal distribution</to>
	<statement>If \(X\) has the log-normal distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(a \in (0, \infty)\), and \(\sigma \in (0, \infty)\), then \(a X\) has the log-normal distribution with location parameter \(\ln(a) + \mu\) and scale parameter \(\sigma\).</statement>
	<type>linear transformation</type>
</relation>

<relation id="log-normal/normal">
	<from>log-normal distribution</from>
	<to>normal distribution</to>
	<statement>If \(X\) has the log-normal distribution with location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\sigma \in (0, \infty)\), then \(\ln(X)\) has the normald distribution with location parameter \(\mu\) and scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Maxwell-Boltzmann/Maxwell-Boltzmann">
	<from>Maxwell-Boltzmann distribution </from>
	<to>Maxwell-Boltzmann distribution</to>
	<statement>If \(X\) has the Maxwell-Boltzmann distribution with scale parameter \(a \in (0, \infty)\) and \(b \in (0, \infty)\), then \(b X\) has the Maxwell-Boltzmann distribution with scale parameter \(a b\).</statement>
	<type>scale transformation</type>
</relation>

<relation id="Maxwell-Boltzman/chi">
	<from>Maxwell-Boltzmann distribution</from>
	<to>chi distribution</to>
	<statement>If \(X\) has the Maxwell-Boltzmann distribution with scale parameter \(a \in (0, \infty)\), then \(\frac{X}{a}\) has the chi distribution with 3 degrees of freedom.</statement>
	<type>scale transformation</type>
</relation>

<relation id="negative-binomial/negative-binomial">
	<from>negative binomial distribution</from>
	<to>negative binomial distribution</to>
	<statement>If \(X\) has the negative binomial distribution with stopping parameter \(r \in (0, \infty)\) and success parameter \(p \in (0, 1)\), \(Y\) has the negative binomial distribution with stopping parameter \(s \in (0, \infty)\) and success parameter \(p\), and \(X\) and \(Y\) are independent, then \(X + Y\) has the negative binomial distribution with stopping parameter \(r + s\) and success parameter \(p\).</statement>
	<type>convolution</type>
</relation>

<relation id="negative-binomial/geometric">
	<from>negative binomial distribution</from>
	<to>geometric distribution</to>
	<statement>The negative binomial distribution with stopping parameter \(1\) and success parameter \(p \in (0, 1)\) is the geometric distribution with success parameter \(p\).</statement>
	<type>special case</type>
</relation>

<relation id="negative-binomial/Poisson">
	<from>negative binomial distribution</from>
	<to>Poisson distribution</to>
	<statement>If \(p_r \in (0, 1)\) for each \(r \in (0, \infty)\) and \(r \frac{p}{1-p} \to \lambda \in (0, \infty)\) as \(r \to \infty\), then the negative binomial distribution with stopping parameter \(r\) and success parameter \(p_r\) converges to the Poisson distribution with parameter \(\lambda\).</statement>
	<type>limiting distribution with respect to parameter</type>
</relation>

<relation id="negative-binomial/standard-normal">
	<from>negative binomial distribution</from>
	<to>standard normal distribution</to>
	<statement>If \(X\) has the negative binomial distribution with stopping parameter \(r \in (0, \infty)\) and success parameter \(p \in (0, \infty)\), then the distribution of \(\frac{p X - r (1 - p)}{\sqrt{r (1 - p}}\) converges to the standard normal distribution at \(r \to \infty\).</statement>
	<type>central limit theorem</type>
</relation>

<relation id="negative-binomial/binomial">
	<from>negative binomial distribution</from>
	<to>binomial distribution</to>
	<statement> For \(k \in \{1, 2, \ldots\}\), let \(Z_k\) denote the number of failures before the \(k\)th success in a sequence of Bernoulli trials with success parameter \(p \in (0, 1)\), so that \(Z_k\) has the negative binomial distribution with stopping parameter \(k\) and success parameter \(p\). Then for \(n \in \{1, 2, \ldots\}\), \(Y_n = \max\{k: k + Z_k \leq n\}\) has the binomial distribution with trial parameter \(n\) and success parameter \(p\).</statement>
	<type>inverse stochastic process</type>
</relation>

<relation id="normal/log-normal">
	<from>normal distribution</from>
	<to>log-normal distribution</to>
	<statement>If \(X\) has a normal distribution with mean \(\mu \in (-\infty, \infty)\) and variance \(\sigma^2\), then \(Y = e^X\) has the log-normal distribution with parameters \(\mu\) and \(\sigma^2\).</statement>
	<type>transformation</type>
</relation>

<relation id="normal/folded-normal">
	<from>normal distribution</from>
	<to>folded normal Distribution</to>
	<statement>If \(X\) is has the normal distribution with mean \(\mu \in (-\infty, \infty)\) and standard deviation \(\sigma \in (0, \infty)\), then \(|X|\) has the folded normal distribution with parameters \(\mu\) and \(\sigma\).</statement>
	<type>transformation</type>
</relation>

<relation id="normal/half-normal">
	<from>normal distribution</from>
	<to>half-normal distribution</to>
	<statement>If \(X\) is has the normal distribution with mean \(\mu\) = 0 and standard deviation \(\sigma \in (0, \infty)\), then \(|X|\) has a half-normal distribution with parameter \(\sigma\).</statement>
	<type>special case</type>
</relation>

<relation id="normal/noncentral-chi-square">
	<from>normal distribution</from>
	<to>non-central chi-square distribution</to>
	<statement>If \(X\)  has the normal distribution with mean \(\mu \in (-\infty, \infty)\) and standard deviation \(\sigma \in (0, \infty)\), then variable \(Y = \frac{X^2}{\sigma^2}\) has a non-central chi-square distribution with one degree of freedom and non-centrality parameter \(\frac{\mu^2}{\sigma^2}\).</statement>
	<type>transformation</type>
</relation>

<relation id="normal/truncated-normal">
	<from>normal distribution</from>
	<to>truncated normal distribution</to>
	<statement>If \(X\) is has the normal distribution with mean \(\mu \in (-\infty, \infty)\) and standard deviation \(\sigma \in (0, \infty)\), and if \(a, b \in [-\infty, \infty]\) with \(a \lt b\), then the conditional distribution of \(X\) given  \(X \in (a,b)\) is the truncated normal distribution with location parameter \(\mu\), scale parameter \(\sigma\), minimum value \(a\), and maximum value \(b\).</statement>
	<type>conditioning</type>
</relation>

<relation id="normal/Levy">
	<from>normal distribution</from>
	<to>Levy distribution</to>
	<statement>If \(X\) has the normal distribution with mean \(\mu \in (-\infty, \infty)\) and standard deviation \(\sigma \in (0, \infty)\), then \(\frac{1}{(X - \mu)^2}\) has the Levy distribution with location parameter 0  and scale parameter \(\frac{1}{\sigma^2}\).</statement>
	<type>transformation</type>
</relation>

<relation id="normal/Rice"> 
	<from>normal distribution</from>
	<to>Rice distribution</to>
	<statement>Let \(\nu \in [0, \infty)\), \(\theta \in (-\infty, \infty)\) and \(\sigma \in (0, \infty)\). If \(X\) has the normal distribution with mean \(\nu \cos(\theta)\) and standard deviation \(\sigma\), \(Y\) has the normal distribution with mean \(\nu \sin(\theta)\) and standard deviation \(\sigma\), and \(X\) and \(Y\) are independent, then \(\sqrt{X^2 + Y^2}\) has the Rice distribution with distance parameter \(\nu\) and scale parameter \(\sigma\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="normal/standard-normal"> 
	<from>normal distribution</from>
	<to>standard normal</to>
	<statement>If \(X\) has the normal distribution with mean \(\mu = 0\) and standard deviation \(\sigma = 1\), then \(X\) has a standard normal distribution.</statement>
	<type>special case</type>
</relation>

<relation id="standard-normal/chi-square">
	<from>standard normal distribution</from>
	<to>chi-square distribution</to>
	<statement>If \(X_1, X_2, \ldots, X_n\) are independent standard normal random variables, then \(\sum_{i=1}^n X_i^2\) has the chi-square distribution with \(n\) degrees of freedom.</statement>
	<type>convolution</type>
</relation>

<relation id="normal/student">
	<from>normal distribution</from>
	<to>Student t-distribution</to>
	<statement>If \(X_1, X_2, \ldots, X_n\) are independent normally distributed random variables with mean \(\mu \in (-\infty, \infty)\) and standard deviation \(\sigma \in (0, \infty)\), then \(T = \frac{\overline{X} - \mu}{S / \sqrt{n}}\) has the Student's t distribution with \(n-1\) degrees of freedom.</statement>
	<type>transformation</type>
</relation>

<relation id="normal/Maxwell-Boltzmann">
	<from>normal distribution </from>
	<to>Maxwell-Boltzmann distribution</to>
	<statement>If \(X_1\), \(X_2\), and \(X_3\) are independent random variables, each with the normal distribuiton with mean \(0\) and standard deviation \(a \in (0, \infty)\), then \(\sqrt{X_1^2 + X_2^2 + X_3^2}\) has the Maxwell-Boltzmann distribution with parameter \(a\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="standard-normal/standard-Cauchy">
	<from>standard normal distribution</from>
	<to>standard Cauchy distribution</to>
	<statement>If \(X\) and \(Y\) are independent variables, each with the standard normal distribution, then \(\frac{X}{Y}\) has the standard Cauchy distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Pareto/Exponential">
	<from>Pareto distribution</from>
	<to>exponential distribution</to>
	<statement>If \(X\) has the Pareto distribution with shape parameter \(a \in (0, \infty)\) and scale parameter \(b \in (0, \infty)\), then \(\ln\left(\frac{X}{b}\right)\) has the exponential distribution with rate parameter \(a\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Pareto/Pareto">
	<from>Pareto distribution</from>
	<to>Pareto distribution</to>
	<statement>If \(X\) has the Pareto distribution with shape parameter \(a \in (0, \infty)\) and scale parameter \(b \in (0, \infty)\), and \(c \in (0, \infty)\) then \(c X\) has the Pareto distribution with shape parameter \(a\) and scale parameter \(b c\).</statement>
	<type>scale transformation</type>
</relation>

<relation id="Pareto/beta">
	<from>Pareto distribution</from>
	<to>beta distribution</to>
	<statement>If \(X\) has the Pareto distribution with shape parameter \(a \in (0, \infty)\) and scale parameter \(b \in (0, \infty)\) then \(\frac{b}{X}\) has the beta distribution with left shape parameter \(a\) and right shape parameter \(1\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Pareto/standard-uniform">
	<from>Pareto distribution</from>
	<to>standard uniform distribution</to>
	<statement>If \(X\) has the Pareto distribution with shape parameter \(a \in (0, \infty)\) and scale parameter \(b \in (0, \infty)\), then \(1 - \left(\frac{b}{X}\right)^a\) has the standard uniform distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Poisson/Poisson">
	<from>Poisson distribution</from>
	<to>Poisson distribution</to>
	<statement>If \(X\) has the Poisson distribution with parameter \(\alpha \in (0, \infty)\), \(Y\) has the Poisson distribution with parameter \(\beta \in (0, \infty)\), and \(X\) and \(Y\) are independent, then \(X + Y\) has the Poisson distribution with parameter \(\alpha + \beta\).</statement>
	<type>convolution</type>
</relation>

<relation id="Poisson/standard-normal">
	<from>Poisson distribution</from>
	<to>standard normal distribution</to>
	<statement>If \(X\) has the Poisson distribution with parameter \(\alpha \in (0, \infty)\), then the distribution of \(\frac{X - \alpha}{\sqrt{\alpha}}\) converges to the standard normal distribution as \(\alpha \to \infty\).</statement>
	<type>central limit theorem</type>
</relation>

<relation id="Poisson/binomial"> 
	<from>Poisson distribution</from>
	<to>binomial distribution</to>
	<statement>If \(\{N_t: t \ge 0\}\) is a Poisson process and if \(s \lt t\), then the conditional distribution of \(N_s\) given \(N_t = n\) is binomial with parameters \(n\) and \(\frac{s}{t}\).</statement>
	<type>conditioning</type>
</relation>

<relation id="Poisson/gamma"> 
	<from>Poisson distribution</from>
	<to>gamma distribution</to>
	<statement>If \(\{N_t: t \ge 0\}\) is a Poisson process with rate parameter \(\alpha \in (0, \infty)\) and \(n \in \{1, 2, \ldots\}\) then \(T = \min\{t \ge 0: N_t = n\}\) has the gamma distsribution with shape parameter \(k\) and scale parameter \(\frac{1}{\alpha}\).</statement>
	<type>stochastic process</type>
</relation>

<relation id="Poisson/logarithmic/negative-binomial">
	<from>Poisson distribution</from>
	<from>logarithmic distribution</from>
	<to>negative binomial distribution</to>
	<statement>If \(\bs{X} =(X_1, X_2, \ldots)\) is a sequence of independent random variables, each with the logarithmic distribution with parameter \(p \in (0, 1)\), \(N\) has the Poisson distribution with parameter \(-r \ln(1 - p)\) where \(r \in (0, \infty)\), and \(N\) and \(\bs{X}\) are independent, then \(\sum_{i=1}^N X_i\) has the negative binomial distribution with stopping parameter \(r\) and sucess parameter \(p\).</statement>
	<type>compound Poisson transformation</type>
</relation>

<relation id="Poisson/gamma/negative-binomial"> 
	<from>Poisson distribution</from>
	<from>gamma distribution</from>
	<to>negative binomial distribution</to>
	<statement>If \(\Lambda\) has the gamma distribution with shape parameter \(r \in (0, \infty)\) and scale parameter \(\frac{p}{1-p}\) where \(p \in (0, 1)\), and the conditional distribution of \(X\) given \(\Lambda = \lambda \in (0, \infty)\) is Poisson with parameter \(\lambda\), then \(X\) has the negative binomial distribution with stopping parameter \(r\) and success parameter \(p\).</statement>
	<type>mixture</type>
</relation>

<relation id="Rademacher/Bernoulli">
	<from>Rademacher distribution</from>
	<to>Bernoulli distribution</to>
	<statement>If \(X\) has the Rademacher distribution then \(\frac{X+1}{2}\) has the Bernoulli distribution with success parameter \(\frac{1}{2}\).</statement>
	<type>linear transformation</type>
</relation>

<relation id="Rayleigh/chi-square">
	<from>Rayleigh distribution</from>
	<to>chi-square distribution</to>
	<statement>If \(X\) has the Rayleigh distribution with scale parameter \(1\), then \(X^2\) has the chi-square distribution with 2 degrees of freedom.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Rayleigh/Rayleigh">
	<from>Rayleigh distribution</from>
	<to>Rayleigh distribution</to>
	<statement>If \(X\) has the Rayleigh distribution with scale parameter \(\sigma \in (0, \infty)\) and \(b \in (0, \infty)\), then \(b X\) has the Rayleigh distribution with scale parameter \(b \sigma\).</statement>
	<type>scale transformation</type>
</relation>

<relation id="Rayleigh/gamma">
	<from>Rayleigh distribution</from>
	<to>gamma distribution</to>
	<statement>If \((X_1, X_2, \ldots, X_n)\) is a sequence of independent random variables, each with the Rayleigh distribution with scale parameter \(\sigma \in (0, \infty)\), then \(\sum_{i=1}^n X_i^2\) has the chi-square distribution with shape parameter \(n\) and scale parameter \(2 \sigma^2\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Rayleigh/standard-uniform">
	<from>Rayleigh distribution</from>
	<to>Standard uniform distribution</to>
	<statement>If \(X\) has the Rayleigh distribution with shape parameter \(\sigma \in (0, \infty)\), then \(1 - \exp\left(-\frac{X^2}{2 \sigma^2}\right)\) has the standard uniform distribution.</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="Rice/Rayleigh">
	<from>Rice distribution</from>
	<to>Rayleigh distribution</to>
	<statement>The Rice distribution with distance parameter \(0\) and scale parameter \(\sigma \in (0, \infty)\) is the Rayleigh distribution with scale parameter \(\sigma\)</statement>
	<type>special case</type>
</relation>

<relation id="Rice/noncentral-chi-square">
	<from>Rice distribution</from>
	<to>noncentral chi-square distribution</to>
	<statement>If \(X\) has the Rice distribution with distance parameter \(\nu \in [0, \infty)\) and scale parameter \(1\), then \(X^2\) has the noncentral chi-square distribution with 2 degrees of freedom and noncentrality parameter \(\nu^2\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="semicircle/standard-uniform">
	<from>semicircle distribution</from>
	<to>standard uniform distribution </to>
	<statement>If \(X\) has the semicircle distribution with radius \(r \in (0, \infty)\) then \(\frac{1}{2} + \frac{1}{\pi r^2} X \sqrt{r^2 - X^2} + \frac{1}{\pi} \arcsin\left(\frac{X}{r}\right)\) has the standard uniform distribution</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="stable/Cauchy">
	<from>stable distribution</from>
	<to>Cauchy distribution</to>
	<statement>If \(X\) has a stable distribution with stability parameter \(\alpha = 1\), skewness parameter \(\beta = 0\), location parameter \(\mu \in (-\infty, \infty)\), and scale parameter \(\gamma \in (0, \infty)\), then \(X\) has a Cauchy distribution with scale parameter \(\gamma\) and location parameter \(\mu\).</statement>
	<type>special case.</type>
</relation>

<relation id="stable/normal">
	<from>stable Distribution</from>
	<to>normal Distribution</to>
	<statement>If \(X\) has a stable distribution with stability parameter \(\alpha = 2\), location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\gamma \in (0, \infty)\), then \(X\) has a normal distribution with mean \(\mu\) and variance \(\sigma^2 = 2 \gamma^2\).</statement>
	<type>special case.</type>
</relation>

<relation id="stable/Levy"> 
	<from>stable Distribution</from>
	<to>Levy Distribution</to>
	<statement>If \(X\) has a stable distribution with stability parameter \(\alpha = \frac{1}{2}\), skewness parameter \(\beta=1\), location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\gamma \in (0, \infty)\), then \(X\) has a Levy distribution with scale parameter \(\gamma\) and shift parameter \(\mu\).</statement>
	<type>special case.</type>
</relation>

<relation id="stable/Landau">
	<from>stable Distribution</from>
	<to>Landau Distribution</to>
	<statement>If \(X\) has a stable distribution with stability parameter \(\alpha = 1\), skewness parameter \(\beta = 1\), location parameter \(\mu \in (-\infty, \infty)\) and scale parameter \(\gamma \in (0, \infty)\) then \(X\) has a Landau distribution with scale parameter \(\gamma\) and location parameter \(\mu\).</statement>
	<type>special case</type>	
</relation>

<relation id="r"> %Student's t to F
	<from>Student's t-distribution</from>
	<to>F-distribution</to>
	<statement>if \(X\) has the Student's t-distribution with \(n \in \{1, 2, \ldots\}\) degrees of freedom, then \(Y = X^2\) has the F distribuiton with \(1\) degree of freedom in the numerator and \(n\) degrees of freedom in the denominator.</statement>
	<type>transformation</type>
</relation>

<relation id="student/Cauchy">
	<from>Student t-distribution</from>
	<to>Cauchy distribution</to>
	<statement>The Student's t-distribution with 1 degree of freedom is the standard Cauchy distribuiton.</statement>
	<type>special case</type>
</relation>

<relation id="U-quadratic/standard-uniform">
	<from>U-quadratic distribution</from>
	<to>standard uniform distribuiton</to>
	<statement>If \(X\) has the U-quadratic distribution with left endpoint \(a \in (-\infty, \infty)\) and right endpoint \(b \in (a, \infty)\) then \(\frac{\alpha}{3} [(X - \beta)^3 + (\beta - \alpha)^3]\) has the standard uniform distribution, where \(\alpha = \frac{12}{(b - a)^3}\) and \(\beta = \frac{a + b}{2}\).</statement>
	<type>nonlinear transformation</type>
</relation>

<relation id="von-Mises/uniform">
	<from>von Mises distribution</from>
	<to>uniform distribution</to>
	<statement>The von Mises distribution with location parameter \(0\) and shape parameter \(0\) is the uniform distribution on the interval \([-\pi, \pi]\).</statement>
	<type>special case</type>
</relation>

<relation id="Wald/Wald.1">
	<from>Wald distribution</from>
	<to>Wald distribution</to>
	<statement>If \(X\) has the Wald distribution with mean \(\mu \in (0, \infty)\) and shape parameter \(\lambda \in (0, \infty)\) and \(t \in (0, \infty)\), then \(t X\) has the Wald distribution with mean \(t \mu\) and shape parameter \(t \lambda\)</statement>
	<type>scale transformation</type>
</relation>

<relation id="Wald/Wald.2"> 
	<from>Wald distribution</from>
	<to>Wald distribution</to>
	<statement>If \(X\) has the Wald distribution with mean \(\mu a\) and shape paramter \(\lambda a^2\) where \(\mu \in (0, \infty)\), \(\lambda \in (0, \infty)\), and \(a \in (0, \infty)\), and if \(Y\) has the Wald distribution with mean \(\mu b\) and shape parameter \(\lambda b\) where \(b \in (0, \infty)\), and if \(X\) and \(Y\) are independent, then \(X + Y\) has the Wald distribution with mean \(\mu(a + b)\) and shape paramter \(\lambda(a^2 + b^2)\).</statement>
	<type>convolution</type>
</relation>

<relation id="Weibull/Weibull">
	<from>Weibull distribution</from>
	<to>Weibull distribution</to>
	<statement>If \(X\) has the Weibull distribution with shape parameter \(k \in (0, \infty)\), scale parameter \(b \in (0, \infty)\), and \(c \in (0, \infty)\), then \(Y = c X\) has the Weibull distribution with shape parameter \(k\) and scale parameter \(b c\).</statement>
	<type>scale transformation</type>
</relation>

<relation id="Weibull/exponential">
	<from>Weibull distribution</from>
	<to>exponential distribution</to>
	<statement>If \(X\) has the Weibull distribution with shape parameter \(k \in (0, \infty)\) and scale parameter \(b \in (0, \infty)\), then \(Y = \left(\frac{X}{b}\right)^k\) has the standard exponential distribution.</statement>
	<type>transformation</type>
</relation>
</relations>

<references>
<reference id="Rogozin 2001" type="article">
	<author>Rogozin, B.A.</author>
	<title>Arcsine distribution</title>
	<publisher>Springer</publisher>
	<year>2001</year>
	<url>http://en.wikipedia.org/wiki/Arcsine_distribution</url>
</reference>
<reference id="Evans Hastings Peacock 2000" type="book">
	<author>Evans, M.</author>
	<author>Hastings, N</author>
	<author>Peacock, B.</author>
	<title>Statistical Distributions, </title>
	<name>Bernoulli distribution</name>
	<publisher>Wiley</publisher>
	<year>2000</year>
	<edition>3rd</edition>
	<address>New York</address>
	<url>http://mathworld.wolfram.com/BernoulliDistribution.html</url>
</reference>
<reference id="Weisstein 2009" type="book">
	<author>Weisstein, Eric W.</author>
	<title>Beta Distribution</title>
	<name>MathWorld</name>
	<url>http://mathworld.wolfram.com/GammaDistribution.html</url>
	<year>2009</year>
</reference>
<reference id="Beyer 1987" type="book">
	<author>Beyer, W. H.</author>
	<title>CRC Standard Mathematical Tables </title>
	<publisher>CRC Press</publisher>
	<year>1987</year>

	<edition>28th</edition>
	<address>Boca Raton, FL</address>
</reference>
<reference id="Papoulis 1962" type="book">
	<author>Papoulis, A.</author>
	<title>The Fourier Integral and Its Applications</title>
	<publisher>McGraw-Hill</publisher>
	<year>1962</year>
	<address>New York</address>
	<url>http://mathworld.wolfram.com/BetaDistribution.html</url>
</reference>
<reference id="Dinov Christou Sanchez 2008" type="article">
	<author>Ivo D. Dinov</author>
	<author>Nicolas Christou</author>
	<author>Juana Sanchez</author>
	<year>2008</year>
	<title>Central Limit Theorem: New SOCR Applet and Demonstration Activity</title>
	<journal>Journal of Statistics Education</journal>
	<volume>16</volume>
	<number>2</number>
	<url>http://www.amstat.org/publications/jse/v16n2/dinov.html</url>
</reference>
<reference id="Dinov Christou Gould 2009" type="article">
	<author>Dinov, ID</author>
	<author>Christou, N</author>
	<author>Gould, R</author>
	<year>2009</year>
	<title>Law of Large Numbers: the Theory, Applications and Technology-based Education</title>
	<journal>JSE</journal>
	<volume>17</volume>
	<number>1</number>
	<page>1-15</page>
</reference>
<reference id="Christou Dinov 2011" type="article">
	<author>Christou N</author>
	<author>Dinov ID</author>
	<year>2011</year>
	<title>Confidence Interval Based Parameter EstimationA New SOCR Applet and Activity</title>
	<journal>PLoS ONE</journal>
	<volume>6</volume>
	<number>5</number>
	<page>e19178</page>
	<doi>10.1371/journal.pone.0019178</doi>
	<url>http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0019178</url>
</reference>
<reference id="Siegrist 2007" type="article">
	<title>Exponential and gamma distributions on positive semigroups, with applications to Dirichlet distributions</title>
	<author>Kyle Siegrist</author>
	<journal>Bernoulli</journal>
	<volume>13</volume>
	<number>2</number>
	<page>330-345</page>
	<year>2007</year>
</reference>
<reference id="Lesser Pearl  2008" type="article">
	<title>Functional Fun in Statistics Teaching: Resources, Research and Recommendations</title>
	<author>Lawrence M. Lesser</author>
	<author>Dennis K. Pearl</author>
	<journal>Journal of Statistics Education</journal> 
	<volume>16</volume>
	<number>3</number>
	<page>330-345</page>
	<year>2008</year>
</reference>
<reference id="Jambunathan 1954" type="article">
	<author>Jambunathan, M. V</author>
	<title>Some Properties of Beta and Gamma Distributions</title>
	<year>1954</year>
	<url>http://mathworld.wolfram.com/BetaDistribution.html</url>
</reference>
<reference id="Grubbs 1962" type="book">
	<author>Grubbs, Frank E.</author>
	<title>Attempts to Validate Certain PERT Statistics or Picking on PERT</title>
	<year>1962</year>
	<url>http://en.wikipedia.org/wiki/Beta_distribution</url>
</reference>
<reference id="Boucher 2007" type="project">
	<report>Wolfram Demonstrations Project</report>
	<author> Chris Boucher</author>
	<title>Binomial distribution</title>
	<year>2007</year>
	<url>http://en.wikipedia.org/wiki/Binomial_distribution</url>
</reference>
<reference id="Minka 2003" type="project">
	<report>Microsoft Technical Report</report>
	<author>Minka, Thomas P.</author>
	<title>Estimating a Dirichlet distribution </title>
	<year>2003</year>
	<url>http://research.microsoft.com/en-us/um/people/minka/papers/dirichlet/</url>
</reference>
<reference id="Kotz et al 2006" type="book">
	<author>S.Kotz et al</author>
	<title>Encyclopedia of Statistical Sciences </title>
	<publisher>Wiley</publisher>
	<year>2006</year>
	<edition>2nd</edition>
	<url>http://en.wikipedia.org/wiki/Cauchy_distribution#References</url>
</reference>
<reference id="Vasicek 1976" type="article">
	<author>Vasicek, Oldrich</author>
	<title>A Test for Normality Based on Sample Entropy</title>
	<journal>Journal of the Royal Statistical Society</journal>
	<year>1976</year>
	<url>http://en.wikipedia.org/wiki/Cauchy_distribution#References</url>
</reference>
<reference id="Rothenberg Fisher Tilanus 1966" type="article">
	<author>Rothenberg, Thomas J.</author>
	<author>Fisher, Franklin, M.</author>
	<author> Tilanus, C.B.</author>
	<title>A note on estimation from a Cauchy sample</title>
	<journal>Journal of the American Statistical Association </journal>
	<year>1966</year>
	<url>http://en.wikipedia.org/wiki/Cauchy_distribution#References</url>
</reference>
<reference id="Freue Gabriella 2007" type="article">
	<author>Cohen Freue</author>
	<author> Gabriella V.</author>
	<title>The Pitman estimator of the Cauchy location parameter</title>
	<journal> Journal of Statistical Planning and Inference </journal>
	<year>2007</year>
	<url>http://faculty.ksu.edu.sa/69424/USEPAP/Coushy%20dist.pdf</url>
</reference>
<reference id="McCullagh 1992" type="article">
	<author>McCullagh, P.</author>
	<title>Conditional inference and Cauchy models </title>
	<journal>Biometrika</journal>
	<year>1992</year>
	<url>http://biomet.oxfordjournals.org/content/79/2/247.abstract</url>
</reference>
<reference id="Simon 2002" type="book">
	<author> M. K. Simon</author>
	<title>Probability Distributions Involving Gaussian Random Variables</title>
	<publisher>Springer</publisher>
	<year>2002</year>
	<address>New York</address>
</reference>
<reference id="" type="book">
	<publisher>Proceedings of the National Academy of Sciences</publisher>
	<author>Wilson, E.B.</author><author> Hilferty, M.M. </author>
	<title> The distribution of chi-square</title><year>1931</year>
	<address> Washington</address>
</reference>
<reference id="Johnson Kotz Balakrishnan 1994" type="book">
	<author>Johnson, N.</author>
	<author>Kotz, S.;</author>
	<author>Balakrishnan, N.</author>
	<title>Continuous Univariate Distributions</title>
	<publisher> Houghton Mifflin</publisher>
	<year>1994</year>
	<edition>2nd</edition>
	<address> Boston, MA</address>
	<url>http://mathworld.wolfram.com/ChiDistribution.html</url>
</reference>
<reference id="Evans Hastings Peacock 2000" type="book">
	<author>Evans, M.</author>
	<author>Hastings, N.</author>
	<author>Peacock, B.</author>
	<title>Chi Distribution</title>
	<publisher>Wiley</publisher>
	<year>2000</year>
	<edition>3rd</edition>
	<address>New York</address>
</reference>
<reference id="Johnson 1994" type="article">
	<author>Johnson, Roger</author>
	<title>Estimating the Size of a Population</title>
	<journal>Teaching Statistics </journal>
	<year>1994</year>
	<url>http://www.rsscse.org.uk/ts/index.htm</url>
</reference>
<reference id="Ritzema 1994" type="book"> 
	<author>Ritzema H.P.</author>
	<title>Drainage Principles and Applications: Frequency and Regression Analysis</title>
	<year>1994</year>
	<url>http://www.waterlog.info/pdf/freqtxt.pdf</url>
</reference>
<reference id="Shasha 1995" type="book">
	<author>Shasha, Dennis</author>
	<author>Cathy Lazere</author>
	<title>Out of Their Minds:The Lives and Discoveries of 15 Great Computer Scientists</title>
	<year>1995</year>
	<publisher>Springer-Verlag</publisher>
	<address>New York</address>
</reference>
<reference id="Lewin 1981" type="book">
	<author>Lewin, L.</author>
	<title> Polylogarithms and Associated Functions</title>
	<year>1981</year>
	<address> North Holland, Amsterdam</address>
	<url>http://en.wikipedia.org/wiki/Exponential-logarithmic_distribution#References</url>
</reference>
<reference id="Tahmasbi Rezaei 2008" type="book">
	<author>Tahmasbi, R.</author>
	<author>Rezaei, S.</author>
	<title>A two-parameter lifetime distribution with decreasing failure rate: Computational Statistics and Data Analysis</title>
	<year>2008</year>
	<url>http://en.wikipedia.org/wiki/Exponential-logarithmic_distribution#References</url>
</reference>
<reference id="Nadarajah 2005" type="article">
	<author>Nadarajah, Saralees</author>
	<title>A generalized normal distribution</title>
	<journal>Journal of Applied Statistics </journal>
	<year>September 2005</year>
</reference>
<reference id="Varanasi Aazhang 1989" type="article">
	<author>Varanasi, M.K.</author>
	<author> Aazhang, B. </author>
	<title>Parametric generalized Gaussian density estimation</title>
	<journal>Journal of the Acoustical Society of America </journal>
	<year>October 1989</year>
</reference>
<reference id="Dominguez-Molina Gonzalez-Faras Rodriguez-Dagnino 2009" type="article">
	<author>Dominguez-Molina, J. Armando</author>
	<author>Gonzalez-Faras, Graciela</author>
	<author>Rodriguez-Dagnino, Ramin M.</author>
	<title>A practical procedure to estimate the shape parameter in the generalized Gaussian distribution</title>
	<year> 2009-03-03</year>
	<url>http://www.cimat.mx/reportes/enlinea/I-01-18_eng.pdf</url>
</reference>
<reference id="Box Tiao 1992" type="book">
	<author>George E. P. Box</author>
	<author>Tiao, George C. </author>
	<title>Bayesian Inference in Statistical Analysis</title>
	<publisher>Wiley</publisher>
	<year>1992</year>
	<address>New York</address>
	<url>http://en.wikipedia.org/wiki/Exponential_power_distribution#References</url>
</reference>
<reference id="Liang Liu Wang 2007" type="article">
	<author>Liang, Faming</author>
	<author>Liu, Chuanhai</author>
	<author>Wang, Naisyin </author>
	<title>A Robust Sequential Bayesian Method For Identification Of Differentially Expressed Genes</title>
	<year>April 2007</year>
	<url>http://www3.stat.sinica.edu.tw/statistica/oldpdf/A17n28.pdf</url>
</reference>
<reference id="Sinz Gerwinn Bethge 2009" type="article">
	<author>Sinz, Fabian</author>
	<author> Gerwinn, Sebastian</author>
	<author> Bethge, Matthias </author>
	<title>Characterization of the p-generalized normal distribution</title>
	<journal>Journal of Multivariate Analysis </journal>
	<year>May 2009</year>
</reference>
<reference id="Kac 1939" type="article">
	<author> Kac, M.</author>
	<title>On a characterization of the normal distribution</title>
	<journal>American Journal of Mathematics </journal>
	<year>1939</year>
	<url>http://en.wikipedia.org/wiki/Exponential_power_distribution#References</url>
</reference>
<reference id="Hosking Wallis 1997" type="article">
	<author>Hosking, J.R.M.</author>
	<author> Wallis, J.R. </author>
	<title>Regional frequency analysis: an approach based on L-moments,</title>
	<publisher>Cambridge University Press</publisher>
	<year>1997</year>
</reference>
<reference id="NIST 2006" type="book">
	<author>NIST</author>
	<title>F-Distribution</title>
	<year>2006</year>
	<url>http://www.itl.nist.gov/div898/handbook/eda/section3/eda3665.htm</url>
</reference>
<reference id="Mood Franklin Boes 1974" type="book">
	<author>Mood, Alexander</author>
	<author> Franklin A. Graybill</author>
	<author>Duane C. Boes</author>
	<title>Introduction to the Theory of Statistics </title>
	<publisher>McGraw-Hill</publisher>
	<year>1974</year>
	<edition>Third Edition</edition>
</reference>
<reference id="Hogg Craig 1978" type="book">
	<author>R. V. Hogg</author>
	<author> A. T. Craig</author>
	<title>Introduction to Mathematical Statistics</title>
	<publisher>Macmillan</publisher>
	<year>1978</year>
	<edition>Fourth Edition</edition>
	<address>New York</address>
	<url>http://en.wikipedia.org/wiki/Gamma_distribution#References</url>
</reference>
<reference id="Choi Wette 1969" type="book">
	<author>S. C. Choi</author>
	<author> R. Wette</author>
	<title>Technometrics</title>
	<year>1969</year>
</reference>
<reference id="Willemse Kaas 2007" type="book">
	<author>Willemse, W. J.</author>
	<author> Kaas, R.</author>
	<title> Insurance: Mathematics and Economics</title>
	<year>2007</year>
</reference>
<reference id="Gumbel 1954" type="book">
	<author>Gumbel, E.J.</author>
	<title>Statistical theory of extreme values and some practical applications</title>
	<publisher>U.S. Department of Commerce</publisher>
	<year>1954</year>
</reference>
<reference id="Ritzema (ed.) 1994" type="book">
	<author>Ritzema (ed.), H.P.</author>
	<title> Frequency and Regression Analysis</title>
	<publisher> International Institute for Land Reclamation and Improvement </publisher>
	<year>1994</year>
	<address>Wageningen, The Netherlands</address>
	<url>http://www.waterlog.info/pdf/freqtxt.pdf</url>
</reference>
<reference id="Talacko 1956" type="article">
	<author>J. Talacko</author>
	<title>Perks' distributions and their role in the theory of Wiener's stochastic variables</title>
	<year>1956</year>
	<url>http://en.wikipedia.org/wiki/Hyperbolic_secant_distribution</url>
</reference>
<reference id="Devroye 1986" type="book">
	<author>Luc Devroye</author>
	<title> Non-Uniform Random Variate Generation</title>
	<publisher>Springer-Verlag</publisher>
	<year>1986</year>
	<address>New York</address>
	<url>http://en.wikipedia.org/wiki/Hyperbolic_secant_distribution</url>
</reference>
<reference id="Hall 1927" type="book">
	<author>Hall, Philip</author>
	<title>The Distribution of Means for Samples of Size N Drawn from a Population in which the Variate Takes Values Between 0 and 1, All Such Values Being Equally Probable</title>
	<publisher>Biometrika</publisher>
	<year>1927</year>
</reference>
<reference id="Irwin 1927" type="book">
	<author>Irwin, J.O.</author>
	<title>On the Frequency Distribution of the Means of Samples from a Population Having any Law of Frequency with Finite Moments, with Special Reference to Pearson's Type II</title>
	<publisher>Biometrika</publisher>
	<year>1927</year>
</reference>
<reference id="Everitt 2002" type="book">
	<author> Everitt, B.S. </author>
	<tilte>The Cambridge Dictionary of Statistics</tilte>
	<year>2002</year>
	<url>http://en.wikipedia.org/wiki/Laplace_distribution#References</url>
</reference>
<reference id="Johnson Kotz Balakrishnan 1995" type="book">
	<author>Johnson, N. L.</author>
	<author> Kotz, S.</author>
	<author>Balakrishnan N.</author>
	<title> Continuous Univariate Distributions</title>
	<year>1995</year>
	<edition>2nd</edition>
	<volume>2</volume>
	<url>http://en.wikipedia.org/wiki/Logistic_distribution</url>
</reference>
<reference id="Balakrishnan 1992" type="book">
	<author>N., Balakrishnan </author>
	<title>Handbook of the Logistic Distribution</title>
	<year>1992</year>
	<edition>Marcel Dekker</edition>
	<address>New York</address>
	<url>http://en.wikipedia.org/wiki/Logistic_distribution</url>
</reference>
<reference id="Aitchison Brown 1957" type="article">
	<author>Aitchison, J.</author>
	<author>Brown, J.A.C. </author>
	<title> The Lognormal Distribution</title>
	<publisher> Cambridge University Press</publisher>
	<year>1957</year>
	<url>http://en.wikipedia.org/wiki/Log-normal_distribution</url>
</reference>
<reference id="Limpert Stahel Abbt 2001" type="book">
	<author>E. Limpert</author>
	<author> W. Stahel </author>
	<author> M. Abbt </author>
	<title>BioScience</title>
	<year>2001</year>
	<url>http://stat.ethz.ch/~stahel/lognormal/bioscience.pdf</url>
</reference>
<reference id="Swamee 2002" type="article">
	<author>Swamee, P.K.</author>
	<title>Near Lognormal Distribution </title>
	<Journal>Journal of Hydrologic Engineering</Journal>
	<year>2002</year>
	<url>http://ascelibrary.org/heo/resource/1/jhyeff/v7/i6/p441_s1?isAuthorized=no</url>
</reference>
<reference id="Leipnik 1991" type="article">
	<author>Roy B. Leipnik</author>
	<title>On Lognormal Random Variables: I - The Characteristic Function</title>
	<journal>Journal of the Australian Mathematical Society Series B</journal>
	<year>1991</year>
	<url>http://journals.cambridge.org/action/displaySpecialPage?pageId=1544</url>
</reference>
<reference id="Gao et al 2009" type="article">
	<author>Gao et al.</author>
	<title> Asymptotic Behaviors of Tail Density for Sum of Correlated Lognormal Variables</title>
	<journal>International Journal of Mathematics and Mathematical Sciences</journal>
	<year>2009</year>
	<url>http://www.hindawi.com/journals/ijmms/2009/630857/</url>
</reference>
<reference id="Brooks Corson Wales 1994" type="book"> 
	Advances in Futures and Options Research
	<author>Robert Brooks</author>
	<author>Jon Corson</author>
	<author> J. Donal Wales</author>
	<title>The Pricing of Index Options When the Underlying Assets All Follow a Lognormal Diffusion </title>
	<year>1994</year>
	<url>http://papers.ssrn.com/sol3/papers.cfm?abstract_id=5735</url>
</reference>
<reference id="Shoukri Mian Tracy 1988" type="article">
	<auhtor>Shoukri, M.M.</auhtor>
	<auhtor>Mian, I.U.M.</auhtor>
	<auhtor>Tracy, D.S.</auhtor>
	<title> Sampling Properties of Estimators of the Log-Logistic Distribution with Application to Canadian Precipitation Data</title>
	<journal> The Canadian Journal of Statistics </journal>
	<year>1988</year>
	<url>http://en.wikipedia.org/wiki/Log-logistic_distribution#References</url>
</reference>
<reference id="Ashkar Mahdi 2006" type="article">
	<author>Ashkar, Fahim</author>
	<author> Mahdi, Smail </author>
	<title>Fitting the log-logistic distribution by generalized moments</title>
	<journal>Journal of Hydrology</journal>
	<year>2006</year>
	<url>http://en.wikipedia.org/wiki/Log-logistic_distribution#References</url>
</reference>
<reference id="Tadikamalla Johnson 1982" type="book">
	<journal>Biometrika</journal>
	<author>Tadikamalla, Pandu R</author>
	<author>Johnson, Norman L.</author>
	<title>Systems of Frequency Curves Generated by Transformations of Logistic Variables</title>
	<year>1982</year>
	<url>http://www.jstor.org/pss/2335422</url>
</reference>
<reference id="Tadikamalla 1980" type="article">
	<author>Tadikamalla, Pandu R.</author>
	<title> A Look at the Burr and Related Distributions</title>
	<journal>International Statistical Review </journal>
	<year>1980</year>
</reference>
<reference id="Bennett 1983" type="article">
	<author>Bennett, Steve</author>
	<title>Log-Logistic Regression Models for Survival Data</title>
	<journal>Applied Statistics</journal>
	<year>1983</year>
	<url>http://www.jstor.org/pss/2347295</url>
</reference>
<reference id="Collett 2003" type="book">
	<author>Collett, Dave</author>
	<title> Modelling Survival Data in Medical Research </title>
	<publisher>CRC press</publisher>
	<year>2003</year>
	<edition>2nd</edition>
</reference>
<reference id="Hosking Wallis 1997" type="article">
	<author>Hosking, Jonathan R. M.</author>
	<author>Wallis, James R</author>
	<title>Regional Frequency Analysis: An Approach Based on L-Moments</title>
	<publisher>Cambridge University Press</publisher>
	<year>1997</year>
	<url>http://en.wikipedia.org/wiki/Log-logistic_distribution#References</url>
</reference>
<reference id="Robson Reed " type="book"> 
	<journal>Flood Estimation Handbook</journal>
	<author> Robson, A.</author>
	<author> Reed, D.</author>
	<title>Statistical Procedures for Flood Frequency Estimation</title>
	<address>Wallingford, UK</address>
	<year>1999</year>
</reference>
<reference id="Ahmad Sinclair Werritty 1988" type="article">
	<author>Ahmad, M. I.</author>
	<author>Sinclair, C. D.</author>
	<author>Werritty, A.</author>
	<title>Log-logistic flood frequency analysis</title>
	<journal>Journal of Hydrology </journal>
	<year>1988</year>
</reference>
<reference id="Villarini Vecchi Smith 2010" type="article">
	<author>Villarini, G.</author>
	<author>Vecchi, G.A.</author>
	<author>Smith, J.A.</author>
	<title>Modeling of the dependence of tropical storm counts in the North Atlantic Basin on climate indices</title>
	<journal>Monthly Weather Review</journal>
	<year>2010</year>
	<url>http://en.wikipedia.org/wiki/Monthly_Weather_Review</url>
</reference>
<reference id="McCullagh Nelder 1989" type="book">
	<author> McCullagh, Peter</author>
	<author> Nelder, John</author>
	<title> Generalized Linear Models</title>
	<publisher>Boca Raton: Chapman and Hall/CRC</publisher>
	<year>1989</year>
	<edition>2nd</edition>
	<url>http://en.wikipedia.org/wiki/Generalized_linear_model</url>
</reference>
<reference id="Cameron Trivedi 1998" type="article">
	<author>Cameron, Adrian C.</author>
	<author> Trivedi, Pravin K. </author>
	<title>Regression analysis of count data</title>
	<publisher>Cambridge University Press</publisher>
	<year>1998</year>
	<url>http://cameron.econ.ucdavis.edu/racd/count.html</url>
</reference>
<reference id="Haldane 1945" type="book">
	<journal>Biometrika</journal>
	<author>J. B. S. Haldane</author>
	<title>On a Method of Estimating Frequencies</title>
	<year>1945</year>
	<url>http://en.wikipedia.org/wiki/Biometrika</url>
</reference>
<reference id="Spencer Paul 1998" type="book">
	<author>Spencer, Paul</author>
	<title> The Pastoral Continuum: the Marginalization of Tradition in East Africa</title>
	<publisher> Clarendon Press</publisher>
	<year>1998</year>
	<address> Oxford </address>
	<url>http://en.wikipedia.org/wiki/Negative_binomial_distribution#References</url>
</reference>
<reference id="Hilbe Joseph 2007" type="book">
	<author>Hilbe, Joseph M.</author>
	<title>Negative Binomial Regression</title>
	<publisher> Cambridge University Press </publisher>
	<year>2007</year>
	<address>Cambridge, UK</address>
</reference>
<reference id="Amari Nagaoka 2000" type="book">
	<author>Amari, Shun-ichi</author>
	<author>Nagaoka, Hiroshi </author>
	<title>Methods of information geometry</title>
	<publisher>Oxford University Press</publisher>
	<year>2000</year>
	<url>http://en.wikipedia.org/wiki/Normal_distribution#References</url>
</reference>
<reference id="Bernardo Smith 2000" type="book">
	<author>Bernardo, J. M.</author>
	<author>Smith, A.F.M. </author>
	<title>Bayesian Theory</title>
	<publisher>Wiley</publisher>
	<year>2000</year>
</reference>
<reference id="Bryc Wlodzimierz 1995" type="book">
	<author>Bryc, Wlodzimierz</author>
	<title> The normal distribution: characterizations with applications</title>
	<year>1995</year>
	<url>http://en.wikipedia.org/wiki/Normal_distribution#References</url>
</reference>
<reference id="Casella Berger 2001" type="book">
	<author>Casella, George</author>
	<author>Berger, Roger L.</author>
	<title>Statistical inference </title>
	<year>2001</year>
	<edition>2nd</edition>
	<address>Duxbury</address>
</reference>
<reference id="Cover Thomas 2006" type="book">
	<author>Cover, T. M.</author>
	<author> Thomas, Joy A.</author>
	<title>Elements of information theory</title>
	<publisher>John Wiley and Sons</publisher>
	<year>2006</year>
</reference>
<reference id="Fan Jianqing 1991" type="book">
	<journal>The Annals of Statistics</journal> 
	<author>Fan, Jianqing</author>
	<title>On the optimal rates of convergence for nonparametric deconvolution problems</title>
	<year>1991</year>
</reference>
<reference id="Galambos Simonelli 2004" type="article">
	<author>Galambos, Janos</author>
	<author>Simonelli, Italo</author>
	<title> Products of random variables: applications to problems of physics and to arithmetical functions</title>
	<publisher> Marcel Dekker, Inc.</publisher>
	<year>2004</year>
</reference>
<reference id="Gould 1981" type="book">
	<author>Stephen Jay Gould</author>
	<title> The mismeasure of man</title>
	<year>1981</year>
	<edition>1st</edition>
	<publisher>W.W. Norton</publisher>
	<url>http://en.wikipedia.org/wiki/The_Mismeasure_of_Man</url>
</reference>
<reference id="Halperin Hartley Hoel 1965" type="book">
	<journal>The American Statistician</journal>
	<author>Halperin, Max</author>
	<author> Hartley, H. O.</author>
	<author> Hoel, P. G.</author>
	<title>Recommended standards for statistical symbols and notation</title>
	<year>1965</year>
</reference>
<reference id="" type="book">
	<author>Hart, John F.</author>
	<title>Computer approximations</title>
	<publisher>John Wiley &amp; Sons</publisher>
	<year>1968</year>
	<address>New York</address>
	<url>http://en.wikipedia.org/wiki/Normal_distribution#References</url>
</reference>
<reference id="Huxley 1932" type="book">
	<author>Huxley, Julian S.</author>
	<title>Problems of relative growth</title>
	<year>1932</year>
	<address>London</address>
</reference>
<reference id="Lukacs King 1954" type="article">
	<jounral>The Annals of Mathematical Statistics</jounral>
	<author>Lukacs, Eugene</author>
	<author>King, Edgar P. </author>
	<title>A property of normal distribution</title>
	<year>1954</year>
</reference>
<reference id="" type="book">
	<author>McPherson, G.</author>
	<title>Statistics in scientific investigation: its basis, application and interpretation</title>
	<publisher>Springer-Verlag</publisher>
	<year>1990</year>
	<url>http://en.wikipedia.org/wiki/Normal_distribution#References</url>
</reference>
<reference id="Marsaglia Tsang 2000" type="article">
	<author>Marsaglia, George</author>
	<author> Tsang, Wai Wan </author>
	<title>The Ziggurat Method for Generating Random Variables</title>
	<jounral>Journal of Statistical Software </jounral>
	<year>2000</year>
	<url>http://www.jstatsoft.org/v05/i08/paper</url>
</reference>
<reference id="Stigler 1978" type="article">
	<author>Stigler, Stephen M. </author>
	<title>Mathematical statistics in the early states</title>
	<jounral>The Annals of Statistics </jounral>
	<year>1978</year>
</reference>
<reference id="Stigler 1982" type="article">
	<author>Stigler, Stephen M.</author>
	<title>A modest proposal: a new standard for the normal</title>
	<journal>The American Statistician </journal>
	<year>1982</year>
</reference>
<reference id="Stigler 1986" type="book">
	<author>Stigler, Stephen M.</author>
	<title> The history of statistics: the measurement of uncertainty before 1900</title>
	<publisher>Harvard University Press</publisher>
	<year>1986</year>
</reference>
<reference id="Arnold 1983" type="book">
	<author>Barry C. Arnold </author>
	<title> Pareto Distributions</title>
	<publisher> International Co-operative Publishing House</publisher>
	<year>1983</year>
	<url>http://en.wikipedia.org/wiki/Pareto_distribution#External_links</url>
</reference>
<reference id="Kleiber Kotz 2003" type="book">
	<author>Christian Kleiber </author>
	<author>Samuel Kotz</author>
	<title>Statistical Size Distributions in Economics and Actuarial Sciences</title>
	<publisher>Willey</publisher>
	<year>2003</year>
</reference>
<reference id="Guerriero Iannace et al 2009" type="article">
	<author>V. Guerriero</author>
	<author> A. Iannace</author>
	<author>S. Mazzoli</author>
	<author>M. Parente</author>
	<author>S. Vitale</author>
	<author>M. Giorgioni </author>
	<title>Quantifying uncertainties in multi-scale studies of fractured reservoir analogues: Implemented statistical analysis of scan line data from carbonate rocks</title>
	<journal> Journal of Structural Geology </journal>
	<year>2009</year>
	<url>http://dx.doi.org/10.1016/j.jsg.2009.04.016</url>
</reference>
<reference id="Ahrens Dieter 1982" type="article">
	<author>Joachim H. Ahrens</author>
	<author>Ulrich Dieter </author>
	<title>Computer Generation of Poisson Deviates</title>
	<journal>ACM Transactions on Mathematical Software </journal>
	<year>1982</year>
	<url>http://portal.acm.org/citation.cfm?id=355997</url>
</reference>
<reference id="Evans Boersma et al 1998" type="article">
	<author>Ronald J. Evans</author>
	<author>J. Boersma</author>
	<author>N. M. Blachman</author>
	<author>A. A. Jagers </author>
	<title>The Entropy of a Poisson Distribution</title>
	<year>1988</year>
</reference>
<reference id="Sijbers den Dekker et al 1998" type="book">
	<author>Sijbers J.</author>
	<author>den Dekker A. J.</author>
	<author>J. Van Audekerke</author>
	<author>Verhoye M.</author>
	<author>Van Dyck D.</author>
	<title>Magnetic Resonance Imaging</title>
	<year>1998 </year>
</reference>
<reference id="Talukdar Lawing 1991" type="article">
	<author>Talukdar, K.K.</author>
	<author>Lawing, William D. </author>
	<title>Estimation of the parameters of the Rice distribution </title>
	<year>1991</year>
	<url>http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal&amp;id=JASMAN000089000003001193000001&amp;idtype=cvips&amp;gifs=yes&amp;ref=no</url>
</reference>
<reference id="Abdi Tepedelenlioglu et al 2001" type="book">
	<author>Abdi, A.</author>
	<author> Tepedelenlioglu, C.</author>
	<author> Kaveh, M.</author>
	<author>Giannakis, G.</author>
	<title>On the estimation of the K parameter for the Rice fading distribution</title>
	<year>2001</year>
	<url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=913150&amp;tag=1</url>
</reference>
<reference id="Bozchalooi Liang 2007" type="article">
	<author>I. Soltani Bozchalooi</author>
	<author>Ming Liang</author>
	<title>A smoothness index-guided approach to wavelet parameter selection in signal de-noising and fault detection</title>
	<journal>Journal of Sound and Vibration</journal>
	<year>2007</year>
	<url>http://www.sciencedirect.com/science?_ob=Articleurl&amp;_udi=B6WM3-4PK8B4Y-7&amp;_user=446478&amp;_coverDate=11%2F20%2F2007&amp;_rdoc=1&amp;_fmt=high&amp;_orig=gateway&amp;_origin=gateway&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_acct=C000020380&amp;_version=1&amp;_urlVersion=0&amp;_userid=446478&amp;md5=b10b8071cb599dcee81b1c353b80d949&amp;searchtype=a</url>
</reference>
<reference id="Bailey 1994" type="article">
	<author>Bailey, R. W.</author>
	<title>Polar generation of random variates with the t-distribution</title>
	<jounral>Mathematics of Computation </jounral>
	<year>1994</year>
</reference>
<reference id="Venables Ripley 2002" type="book">
	<author>W.N. Venables</author>
	<author>B.D. Ripley</author>
	<title>Modern Applied Statistics with S</title>
	<publisher>Springer</publisher>
	<year>2002</year>
	<edition>4th</edition>
	<url>http://en.wikipedia.org/wiki/T-distribution#References</url>
</reference>
<reference id="Gelman Carlin et al 2003" type="book">
	<author>Gelman, Andrew</author>
	<author>John B. Carlin</author>
	<author>Hal S. Stern</author>
	<author>Donald B. Rubin </author>
	<title> Bayesian Data Analysis </title>
	<publisher>CRC/Chapman &amp; Hall</publisher>
	<year>2003</year>
	<edition>2nd</edition>
	<url>http://www.stat.columbia.edu/~gelman/book/</url>
</reference>
<reference id="" type="book">
	<author>Borradaile, Graham<title> Statistics of Earth Science Data</title><publisher>Springer</publisher><year>2003</year><url>http://books.google.com/books?id=R3GpDglVOSEC&amp;printsec=frontcover&amp;source=gbs_navlinks_s#v=onepage&amp;q&amp;f=false</url></author>
</reference>
<reference id="Mardia Jupp 1999" type="book">
	<author>Mardia, Kanti V.</author>
	<author>Jupp, Peter E.</author>
	<title>Directional Statistics</title>
	<publisher>Wiley</publisher>
	<year>1999</year>
	<address>New York</address>
</reference>
<reference id="Fisher 1993" type="book">
	<author>Fisher, Nicholas I.</author>
	<title> Statistical Analysis of Circular Data</title>
	<year>1993</year>
	<address>New York</address>
</reference>
<reference id="Chhikara 1989" type="book">
	<author>Raj Chhikara </author>
	<author> Leroy Folks</author>
	<title>The inverse gaussian distribution: theory, methodology, and applications </title>
	<year>1989</year>
</reference>
<reference id="Seshadri 1993" type="book">
	<author>V. Seshadri</author>
	<title>The Inverse Gaussian Distribution </title>
	<publisher>Oxford Univ Press</publisher>
	<year>1993</year>
</reference>
<reference id="Sagias 2005" type="article">
	<author>Sagias, Nikos C.</author>
	<author>Karagiannidis, George K.</author>
	<title>Gaussian class multivariate Weibull distributions: theory and applications in fading channels</title>
	<journal>Transactions on Information Theory </journal>
	<year>2005</year>
</reference>
</references>
</distributome>
